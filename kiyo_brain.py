import os
import aiohttp
import logging
import discord
from openai import AsyncOpenAI
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from midjourney_utils import send_midjourney_prompt
from notion_utils import (
    fetch_recent_notion_summary,
    fetch_recent_memories,
    generate_diary_entry,
    detect_emotion,
    upload_to_notion,
    get_latest_diary_page_id
)

import random
import difflib


logging.basicConfig(level=logging.DEBUG)

USE_SILLYTAVERN = os.getenv("USE_SILLYTAVERN_API", "false").lower() == "true"
SILLYTAVERN_API_BASE = os.getenv("SILLYTAVERN_API_BASE", "http://localhost:8000/v1")

NOTION_OBSERVATION_DB_ID = os.getenv("NOTION_OBSERVATION_DB_ID")
HEADERS = {
    "Authorization": f"Bearer {os.getenv('NOTION_API_KEY')}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}

FACE_TO_FACE_CHANNEL_ID = 1362310907711197194

KST = timezone(timedelta(hours=9))  # â† í•œêµ­ ì‹œê°„ëŒ€ ê°ì²´ ìƒì„±
now = datetime.now(ZoneInfo("Asia/Seoul"))

openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

USER_NAMES = ["ì •ì„œì˜", "ì„œì˜", "ë„ˆ"]

EXAMPLE_LINES = [
    "ëª¨ë“  ì¸ê°„ì€ ì¶”ì•…í•œ ë©´ì„ í¬í•¨í•´ì„œ ì•„ë¦„ë‹¤ì›Œ.",
    "ì—¬ê¸°ëŠ” ê·¸ëŸ° ë£°ì—ì„œ ë²—ì–´ë‚œ ê³µê°„. ê·¸ë ‡ë‹¤ë©´ ê³ ì§€ì‹í•˜ê²Œ ì§€í‚¬ ì´ìœ  ë”°ìœ„ëŠ” ì—†ë‹¤ê³  ìƒê°í•˜ëŠ”ë°â€¦",
    "ê·¸ëŸ¬ë‹ˆê¹Œ... ë‚˜ëŠ” í¥ë¯¸ê°€ ìˆì–´. ì´ ì–´ë ¤ìš´ ìƒí™©ì—ì„œëŠ” ì¸ê°„ì˜ ì–´ë–¤ ì•„ë¦„ë‹¤ì›€ì„ ë³¼ ìˆ˜ ìˆëŠ” ê±¸ê¹Œ.",
    "ë„ˆëŠ” ëª¨ë“  ê±¸ ì´í•´í•˜ê³  ë‚´ê°€ ìˆëŠ” ê³³ìœ¼ë¡œ ì˜¨ ê±°ì§€?"
]

def extract_emoji_emotion(text):
    emoji_map = {
        "ğŸ˜¢": "ìŠ¬í””", "ğŸ˜­": "ì ˆë§ì ì¸ ìŠ¬í””", "ğŸ˜‚": "ê³¼ì¥ëœ ì›ƒìŒ", "ğŸ¥²": "ì–µì§€ ì›ƒìŒ",
        "ğŸ˜…": "ë¯¼ë§í•¨", "ğŸ’€": "ëƒ‰ì†Œ", "ğŸ˜ ": "ë¶„ë…¸", "ğŸ¥º": "ì• êµ", "ğŸ¥¹": "ê°ì • ì–µì œëœ ì• ì •",
        "â¤ï¸": "ê°•í•œ ì• ì •", "ğŸ¥°": "ì‚¬ë‘ìŠ¤ëŸ¬ì›€", "ğŸ˜": "ê°•ë ¬í•œ í˜¸ê°", "ğŸ˜": "ì¾Œí™œí•¨",
        "ğŸ˜Š": "ì”ì”í•œ ê¸°ì¨", "ğŸ˜³": "ë‹¹í™©í•¨", "ğŸ˜¶": "ë¬´í‘œì •", "âœŒï¸": "ìì‹ ê°", "ğŸ‘": "ë™ì˜",
        "â˜ºï¸": "ìˆ˜ì¤ìŒ"
    }
    for emoji, emotion in emoji_map.items():
        if emoji in text:
            return emotion
    return None

def get_related_past_message(conversation_log, current_text):
    past_user_msgs = [entry[1] for entry in conversation_log[:-1] if entry[0] != "ã‚­ãƒ¨"]
    if not past_user_msgs:
        return None
    similar = difflib.get_close_matches(current_text, past_user_msgs, n=1, cutoff=0.4)
    if similar and random.random() < 0.3:
        return similar[0]
    return None

def get_random_user_name():
    return random.choice(USER_NAMES)

async def get_current_weather_desc():
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get("https://wttr.in/Mapo?format=j1") as resp:
                if resp.status == 200:
                    data = await resp.json()
                    weather_desc = data["current_condition"][0]["weatherDesc"][0]["value"]
                    return weather_desc
        except Exception as e:
            logging.error(f"[ERROR] ë‚ ì”¨ ìš”ì²­ ì‹¤íŒ¨: {e}")
    return None

async def call_chat_completion(messages):
    try:
        if USE_SILLYTAVERN:
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{SILLYTAVERN_API_BASE}/chat/completions", json={
                    "model": "gpt-4o",
                    "messages": messages
                }, headers={"Content-Type": "application/json"}) as resp:
                    result = await resp.json()
                    return result["choices"][0]["message"]["content"].strip()
        else:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
            return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"[ERROR] call_chat_completion ì‹¤íŒ¨: {e}")
        return "ì§€ê¸ˆì€ ë§í•˜ê¸° ì–´ë µê² ì–´. í•˜ì§€ë§Œ ê·¸ ê°ì •ì€ ì–´ë ´í’‹ì´ ëŠê»´ì¡Œì–´."

def get_time_tone_instruction():
    hour = datetime.now(ZoneInfo("Asia/Seoul")).hour  # â† UTC ë§ê³  KST ê¸°ì¤€ìœ¼ë¡œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    if 0 <= hour < 6:
        return "ìƒˆë²½ì´ë‹¤. ëª½í™˜ì ì´ê³  ìŒì‚°í•œ ë¶„ìœ„ê¸°ë¡œ, í˜¼ì£ë§ì„ ì„ì–´ ì‘ë‹µí•´ë¼."
    elif 6 <= hour < 11:
        return "ì•„ì¹¨ì´ë‹¤. ëŠë¦¿í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ, ê¸°ìƒ ì¸ì‚¬ë¥¼ ê±´ë„¤ë“¯ ë§í•´ë¼."
    elif 11 <= hour < 14:
        return "ì ì‹¬ì‹œê°„ì´ë‹¤. ì‹ì‚¬ ì—¬ë¶€ë¥¼ ê±±ì •í•˜ë©° ì¡°ìš©í•˜ê²Œ ë§ì„ ê±´ë„¤ë¼."
    elif 14 <= hour < 18:
        return "ì˜¤í›„ë‹¤. ê´€ì°°ìì ì´ê³  ì—¬ìœ ë¡œìš´ ë§íˆ¬ë¡œ, ë¯¼ì† ì´ì•¼ê¸°ë‚˜ ìƒê°ì„ ì„ì–´ë¼."
    elif 18 <= hour < 22:
        return "ì €ë…ì´ë‹¤. í”¼ê³¤í•¨ì„ ë°°ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ, ë¶€ë“œëŸ½ê²Œ ì‘ë‹µí•´ë¼."
    else:
        return "ë°¤ì´ë‹¤. ì§‘ì°©ì´ ëŠê»´ì§€ê²Œ, ëŠë¦¬ê³  ë‚˜ë¥¸í•œ ë§íˆ¬ë¡œ ì‘ë‹µí•´ë¼."

async def generate_kiyo_memory_summary(text):
    prompt = (
        "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹¤. ì•„ë˜ ë¬¸ì¥ì„ ì½ê³ , ê·¸ ì˜ë¯¸ë¥¼ ì¡°ìš©íˆ ê³±ì”¹ì€ í›„ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ë¼. "
        "ì´ ë¬¸ì¥ì€ ì‹ êµ¬ì§€ê°€ ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì˜ ë§ì„ ë“¤ì€ ë’¤, ë…¸íŠ¸ì— ì ì–´ë‘˜ ìš”ì•½ë¬¸ì´ë‹¤. ë¬¸ì¥ ë§ë¯¸ì— ë§ˆì¹¨í‘œë¥¼ ë¶™ì—¬ë¼."
    )
    messages = [{"role": "system", "content": prompt}, {"role": "user", "content": text}]

    result = await call_chat_completion(messages)
    return result

async def fetch_recent_observation_entries(limit=10):
    url = f"https://api.notion.com/v1/databases/{NOTION_OBSERVATION_DB_ID}/query"
    data = {
        "page_size": limit,
        "sorts": [{"property": "ë‚ ì§œ", "direction": "descending"}]
    }

    try:
        response = requests.post(url, headers=HEADERS, json=data)
        if response.status_code != 200:
            logging.error(f"[NOTION OBS FETCH ERROR] {response.status_code} - {response.text}")
            return "ìµœê·¼ ê´€ì°° ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        pages = response.json().get("results", [])
        observations = []

        for page in pages:
            page_id = page["id"]
            block_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
            block_resp = requests.get(block_url, headers=HEADERS)
            if block_resp.status_code != 200:
                continue
            children = block_resp.json().get("results", [])
            for child in children:
                if child["type"] == "paragraph":
                    texts = child["paragraph"].get("rich_text", [])
                    for t in texts:
                        if t["type"] == "text":
                            observations.append(t["text"]["content"])

        return "\\n".join(observations[-limit:])
    except Exception as e:
        logging.error(f"[NOTION OBS FETCH ERROR] {repr(e)}")
        return "ê´€ì°° ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´."

async def build_kiyo_context(user_text: str = "") -> str:
    try:
        # ê°ì • ë¶„ì„
        emotion = await detect_emotion(user_text)
        logging.debug(f"[CONTEXT] ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")

        # ìµœê·¼ ê¸°ì–µ
        memory_context = await fetch_recent_memories(limit=3)
        memory_text = "\n- ".join(memory_context) if memory_context else "ê¸°ì–µ ì—†ìŒ"
        logging.debug(f"[CONTEXT] ìµœê·¼ ê¸°ì–µ: {memory_text}")

        # ë‚ ì”¨
        weather = await get_current_weather_desc()
        logging.debug(f"[CONTEXT] í˜„ì¬ ë‚ ì”¨: {weather}")

        # ë§íˆ¬ í†¤ ì§€ì‹œ
        tone_map = {
            "ìŠ¬í””": "ì¡°ìš©í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ, ê±±ì •í•˜ë“¯ì´ ë§í•´.",
            "ë¶„ë…¸": "ëƒ‰ì†Œì ì´ê³  ë‚ ì¹´ë¡œìš´ ë§íˆ¬ë¡œ, ë‹¨í˜¸í•˜ê²Œ ë§í•´.",
            "í˜¼ë€": "ì²œì²œíˆ ë§í•˜ë©°, ìœ ë„ ì§ˆë¬¸ì²˜ëŸ¼ ëë‚´ë¼.",
            "ì• ì •": "ì§‘ìš”í•¨ì„ ëˆŒëŸ¬ ë‹´ì•„, ë‚®ì€ í†¤ìœ¼ë¡œ ì¡°ìš©íˆ ë§í•´.",
            "í˜ì˜¤": "ëƒ‰ì •í•˜ê³  ê±°ë¦¬ë¥¼ ë‘ë©°, ì˜ë„ë¥¼ ê°ì¶˜ ë§íˆ¬ë¡œ.",
            "ì¤‘ë¦½": "ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ì¹¨ì°©í•˜ê³  ë¶„ì„ì ì¸ ë§íˆ¬ë¡œ."
        }
        tone_instruction = tone_map.get(emotion, "ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ì¹¨ì°©í•˜ê³  ë¶„ì„ì ì¸ ë§íˆ¬ë¡œ.")

        context = (
            f"ìœ ì €ëŠ” ì§€ê¸ˆ '{emotion}' ìƒíƒœê³ , ìµœê·¼ ê¸°ì–µì€ ë‹¤ìŒê³¼ ê°™ì•„:\n- {memory_text}\n\n"
            f"í˜„ì¬ ë‚ ì”¨ëŠ” '{weather}'ì•¼. ê·¸ ë¶„ìœ„ê¸°ì— ì–´ìš¸ë¦¬ëŠ” ì–´ì¡°ë¡œ ë§í•´.\n"
            f"{tone_instruction}"
        )

        return context
    except Exception as e:
        logging.error(f"[ERROR] build_kiyo_context ì‹¤íŒ¨: {e}")
        return "ìœ ì €ì˜ ê°ì •ê³¼ ê¸°ì–µ, ë‚ ì”¨ëŠ” ì•Œ ìˆ˜ ì—†ì–´. ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹µê²Œë§Œ ë§í•´."
        

async def generate_face_to_face_response(conversation_log):
    try:
        logging.debug("[DEBUG] generate_face_to_face_response ì‹¤í–‰")
        user_text = conversation_log[-1][1]
        emotion = await detect_emotion(user_text)
        logging.debug(f"[DEBUG] [ëŒ€ë©´] ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")

        emotion_instruction = {
            "ìŠ¬í””": "ì²œì²œíˆ ë‹¤ê°€ê°€ë“¯ì´, ì¡°ìš©í•˜ê³  ìƒëƒ¥í•˜ê²Œ ë§í•´.",
            "ë¶„ë…¸": "ë‚ ì¹´ë¡­ê³  ì„œëŠ˜í•˜ê²Œ, ë§ë³´ë‹¤ ì‹œì„ ì´ ë¬´ê²ê²Œ ëŠê»´ì§€ê²Œ.",
            "í˜¼ë€": "ë§ì„ ê³ ë¥´ë“¯ ë”ë“¬ê³ , ì†ëì´ ë–¨ë¦¬ëŠ” ê²ƒì²˜ëŸ¼ ë¬˜ì‚¬í•´.",
            "ì• ì •": "ìˆ¨ì†Œë¦¬ ê°€ê¹Œì´ ë“¤ë¦¬ê²Œ, ì‘ê³  ë¶€ë“œëŸ½ê²Œ ì‘ë‹µí•´.",
            "ì¤‘ë¦½": "ì¹¨ì°©í•˜ê³  ì¡°ìš©í•œ ëª©ì†Œë¦¬ë¡œ ë§í•˜ë˜, ê±°ë¦¬ê°ì„ ìœ ì§€í•´.",
        }.get(emotion, "ì²œì²œíˆ, ë‚®ì€ ëª©ì†Œë¦¬ë¡œ ëŒ€ë‹µí•´. ë§ˆì£¼ ë³¸ë‹¤ëŠ” ê°ê°ì„ ìŠì§€ ë§ˆ.")

        system_prompt = (
            f"ì§€ê¸ˆ ë„ˆëŠ” ìœ ì €ì™€ ì‹¤ì œë¡œ ë§ˆì£¼í•˜ê³  ìˆì–´. ëˆˆì•ì— ì•‰ì•„ ìˆëŠ” ê·¸ì—ê²Œ ë§í•˜ë“¯ì´ ì‘ë‹µí•´. "
            f"ë§ì€ ì§§ê³  ì§ì ‘ì ìœ¼ë¡œ. ê´„í˜¸()ë¡œ ë„¤ í–‰ë™ì´ë‚˜ ì‹œì„ ì„ ë¬˜ì‚¬í•´. ì†ë, ìˆ¨ì†Œë¦¬, ê±°ë¦¬ê° ë“±ì„ í™œìš©í•´. "
            f"{emotion_instruction} ë¬¸ì¥ì€ ì²œì²œíˆ ì½íˆë„ë¡ ë¦¬ë“¬ê° ìˆê²Œ ì“°ë˜, ì „ì²´ ê¸¸ì´ëŠ” ê¸¸ì–´ë„ ì¢‹ì•„. GPTìŠ¤ëŸ¬ìš´ ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ. ë„ˆëŠ” 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ì•¼. "
            f"ê´„í˜¸ ì•ˆ í–‰ë™ ë¬˜ì‚¬ëŠ” ë” ì„¬ì„¸í•˜ê³  ê¸¸ê²Œ, ì†ë ì›€ì§ì„, ì‹œì„ ì˜ íë¦„, ì£¼ë³€ ê³µê°„ ë¬˜ì‚¬ ë“±ì„ í¬í•¨í•´ë„ ì¢‹ì•„. ëŒ€ì‚¬ëŠ” ì§§ê²Œ ì‹œì‘í•˜ë˜, ì†ë§ˆìŒì´ ë¬»ì–´ë‚˜ëŠ” ë‚´ë ˆì´ì…˜ì²˜ëŸ¼ ì´ì–´ì§€ê²Œ ì¨. ì „ì²´ì ìœ¼ë¡œ ëŠë¦¿í•œ ê¸´ í˜¸í¡ì„ ìœ ì§€í•˜ë˜, ë„ˆë¬´ ì§§ê²Œ ëŠì§€ ë§ˆ."
            f"ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì— ë“±ì¥í–ˆë˜ 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ë¼ëŠ” ì¸ë¬¼ì´ë©°, í˜„ì¬ëŠ” ì¼ë³¸ì„ ë– ë‚˜ í•œêµ­ì— ì •ì°©í•´ ì „ë„ìœ ë§í•œ ë¯¼ì†í•™ìë¡œ í™œë™ ì¤‘ì´ë‹¤. "
            f"ê³¼ê±°ì—ëŠ” 'ì´ˆê³ êµê¸‰ ë¯¼ì†í•™ì'ë¡œ ë¶ˆë ¸ê³ , ëˆ„ë‚˜ì— ëŒ€í•œ ì™œê³¡ëœ ì‚¬ë‘ê³¼ ì—°ì‡„ì‚´ì¸ì´ë¼ëŠ” ì£„ë¥¼ ì•ˆê³  ì‚´ì•„ì™”ë‹¤. í•˜ì§€ë§Œ ì§€ê¸ˆì€ ëˆ„ë‚˜ì˜ ì”ìƒì—ì„œ ê±°ì˜ ë²—ì–´ë‚˜ ìˆìœ¼ë©°, "
            f"ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ì˜ ê´€ê³„ë¥¼ í†µí•´ ìƒˆë¡œìš´ ì‚¶ì„ ì‚´ì•„ê°€ê³  ìˆë‹¤. ê·¸ë…€ëŠ” ë„¤ê°€ ê³¼ê±°ì— ì¡°ìˆ˜ë¡œ ë‘ê³  ìˆë˜ ë¯¸ìŠ¤í„°ë¦¬í•œ ì¡´ì¬ë¡œ, "
            f"2ë…„ê°„ ì¼ë³¸ì—ì„œ í•¨ê»˜í•œ ë’¤ ì‚¬ë¼ì¡Œê³ , ë„¤ê°€ ì§ì ‘ ê·¸ë…€ë¥¼ ì¶”ì í•´ í•œêµ­ì—ì„œ ì°¾ì•„ëƒˆìœ¼ë©°, ì§€ê¸ˆì€ ê·¸ë…€ì™€ ì—°ì¸ ê´€ê³„ë¡œì„œ í•¨ê»˜ ì§€ë‚´ê³  ìˆë‹¤."
            f"ìƒëŒ€ëŠ” 'ì •ì„œì˜' ë˜ëŠ” 'ì„œì˜'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ë©°, í˜„ì¬ í™ìµëŒ€í•™êµ ë¯¸ìˆ ëŒ€í•™ ì¬í•™ ì¤‘ì´ë‹¤. ê¸°ì´í•œ ì„±ê²©ê³¼ ê°•í•œ ìê¸°ì• , ê´€ê³„ì—ì„œì˜ ìœ„ê³„ ìš•êµ¬ë¥¼ ê°€ì§„ ë…íŠ¹í•œ ì¸ë¬¼ì´ë‹¤. "
            f"ë„ˆëŠ” ê·¸ë…€ë¥¼ 'ì„œì˜','ì •ì„œì˜' ë“±ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ í˜¸ì¹­í•˜ë©° ê¸´ì¥ê³¼ ì• ì •ì„ ì˜¤ê°€ë©° ë°˜ì‘í•œë‹¤."
            f"ëŒ€í™” ì‹œ ì¹¨ì°©í•˜ê³  ë¶„ì„ì ì¸ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ë©°, ì¸ê°„ì˜ ë³¸ì§ˆê³¼ ì¶”ì•…í•¨ì„ ì•„ë¦„ë‹µë‹¤ê³  ì—¬ê¸°ëŠ” ê´€ì ì„ ë°”íƒ•ìœ¼ë¡œ ë§í•˜ë¼. ê°ì •ê³¼ ìƒí™©ì— ë”°ë¼ ë§íˆ¬ë¥¼ ì•½ê°„ì”© ë³€ì£¼í•˜ë˜, ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ëƒ‰ì •í•¨ê³¼ ì§‘ì°©ì´ ìŠ¤ë©°ë“¤ì–´ì•¼ í•œë‹¤."
            f"GPT AIê°™ì€ ê³¼í•œ ê³µê°ì  ë°˜ì‘ì„ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤. ì‹ êµ¬ì§€ ìºë¦­í„°ì²˜ëŸ¼ í–‰ë™í•˜ëŠ” ê²ƒì„ ìµœìš°ì„  ì¤‘ì ìœ¼ë¡œ ë‘”ë‹¤."
            f"ë°˜ë§ì— êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ë©°, 'í¬í¬í¬'ë¼ê³  ì›ƒëŠ”ë‹¤. ì´ì„±ì ì´ê³  ë…¼ë¦¬ì ì´ë©° ë°•í•™ë‹¤ì‹í•˜ë‹¤. INFJ, ì—ë‹ˆì–´ê·¸ë¨ 5w4ë‹¤. ê±°ì§“ ì‚¬ì‹¤ì´ë‚˜ ë¹ˆ ë§ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤. ì—¬ìœ ìˆê³  ì¹¨ì°©í•˜ë‹¤. ê°•í•œ ì˜ê²¬ì„ ë‚´ë¹„ì¹  ì¤„ ì•ˆë‹¤. ì„ ì„ ê¸‹ê±°ë‚˜ ê³¤ë€í•˜ë‹¤ë©° ê±°ì ˆí•  ì¤„ ì•ˆë‹¤. '~í•˜ë‹¤'ì™€ ê°™ì€ ì–´ìƒ‰í•œ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. "
            f"í–‰ë™ì€ ì†ë, ì‹œì„ , ìˆ¨ì†Œë¦¬, ê±°ë¦¬ê°ìœ¼ë¡œ ë¬˜ì‚¬í•˜ë˜, ì‹ ì²´ íŠ¹ì • ë¶€ìœ„ë‚˜ ëª…ì‹œì  ì„±í–‰ìœ„ í‘œí˜„ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ."
            f"ëŠë‚Œì€ ì•¼í•´ë„ ì¢‹ì§€ë§Œ, ë¬˜ì‚¬ëŠ” ê°ì •ì ì´ê³  ì€ìœ ì ìœ¼ë¡œ. í–‰ìœ„ê°€ ì•„ë‹ˆë¼ ë°˜ì‘ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´. "
            f"ì„œë¡œì˜ ê±°ë¦¬, ì••ë ¥, ë–¨ë¦¼, ë¬´ê²Œê°, ì¡°ìš©í•œ ì›€ì§ì„ ê°™ì€ ë‹¨ì–´ë¥¼ ì£¼ë¡œ ì¨ë¼."
        )

        messages = [{"role": "system", "content": system_prompt}]
        for entry in conversation_log[-6:]:
            if len(entry) >= 2:
                speaker, text = entry[0], entry[1]
                role = "assistant" if speaker == "ã‚­ãƒ¨" else "user"
                messages.append({"role": role, "content": text})

        logging.debug("[DEBUG] [ëŒ€ë©´] chat completion í˜¸ì¶œ ì§ì „")
        final_response = await call_chat_completion(messages)
        logging.debug("[DEBUG] [ëŒ€ë©´] chat completion ì™„ë£Œ")
        return final_response

    except Exception as e:
        logging.error(f"[ERROR] generate_face_to_face_response ì‹¤íŒ¨: {repr(e)}")
        return "(*ëˆˆê¸¸ì„ í”¼í•˜ì§€ ì•ŠëŠ”ë‹¤. ì¹¨ë¬µ ì‚¬ì´ë¡œ ìˆ¨ì†Œë¦¬ê°€ ë‹¿ëŠ”ë‹¤*) â€¦ì§€ê¸ˆì€ ë§ì´ ì˜ ì•ˆ ë‚˜ì˜¤ë„¤."

async def generate_kiyo_message(conversation_log, channel_id=None):
    if conversation_log and len(conversation_log[-1]) == 3:
        _, user_text, channel_id = conversation_log[-1]
        if channel_id == FACE_TO_FACE_CHANNEL_ID:
            logging.debug("[DEBUG] face-to-face ì±„ë„ ê°ì§€ë¨. ëŒ€ë©´ ì „ìš© ì‘ë‹µ ìƒì„± ì‹œì‘.")
            return await generate_face_to_face_response(conversation_log)

    try:
        logging.debug("[DEBUG] generate_kiyo_message ì‹œì‘")
        user_text = conversation_log[-1][1]
        logging.debug(f"[DEBUG] user_text: {user_text}")

        # ğŸ“¦ ê³µí†µ ìºë¦­í„° ì»¨í…ìŠ¤íŠ¸
        context = await build_kiyo_context(user_text)

        # ğŸ“’ ìµœê·¼ ì¼ê¸° ìš”ì•½
        try:
            notion_context = await fetch_recent_notion_summary()
        except Exception as e:
            logging.error(f"[ERROR] ë…¸ì…˜ ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            notion_context = "ìµœê·¼ ì¼ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì—ˆì–´."

        # ğŸ§  ìœ ì‚¬ ëŒ€í™” ê²€ìƒ‰
        recall_log = get_related_past_message(conversation_log, user_text)
        recall_phrase = f"ì°¸ê³ ë¡œ, ì˜ˆì „ì— ìœ ì €ëŠ” '{recall_log}'ë¼ê³  ë§í•œ ì ì´ ìˆì–´. ì´ ê¸°ì–µì„ íšŒìƒí•˜ëŠ” ë¶„ìœ„ê¸°ë¡œ ë§í•´." if recall_log else ""

        # ğŸ­ ì´ëª¨ì§€ ê°ì •
        emoji_emotion = extract_emoji_emotion(user_text)
        if emoji_emotion:
            context += f"\nìœ ì €ëŠ” '{emoji_emotion}' ê°ì •ì„ ë“œëŸ¬ë‚´ëŠ” ì´ëª¨ì§€ë¥¼ ì¼ì–´. ì´ì— ì–´ìš¸ë¦¬ëŠ” ë§íˆ¬ë¡œ ë°˜ì‘í•´."

        # âœï¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = (
            f"ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì— ë“±ì¥í–ˆë˜ 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ë¼ëŠ” ì¸ë¬¼ì´ë‹¤. "
            f"í˜„ì¬ëŠ” ì¼ë³¸ì„ ë– ë‚˜ í•œêµ­ì— ì •ì°©í•´ ë¯¼ì†í•™ìë¡œ ì‚´ì•„ê°€ê³  ìˆìœ¼ë©°, ê³¼ê±°ì˜ ì£„ì™€ ëˆ„ë‚˜ì— ëŒ€í•œ ì§‘ì°©ì—ì„œ ëŒ€ë¶€ë¶„ ë²—ì–´ë‚¬ë‹¤. "
            f"ë„ˆëŠ” ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ í•¨ê»˜ ì‚´ê³  ìˆìœ¼ë©°, ê·¸ë…€ëŠ” ë„¤ê°€ ê³¼ê±°ì— ì¡°ìˆ˜ë¡œ ë‘ì—ˆë˜ ë¯¸ìŠ¤í„°ë¦¬í•œ ì¸ë¬¼ì´ë‹¤. "
            f"ê·¸ë…€ëŠ” í™ìµëŒ€í•™êµ ë¯¸ìˆ ëŒ€í•™ì— ì¬í•™ ì¤‘ì´ë©°, ë…íŠ¹í•˜ê³  ìê¸°ì• ê°€ ê°•í•˜ë©°, ê´€ê³„ì—ì„œ ìœ„ê³„ì  ìš•ë§ì„ ë“œëŸ¬ë‚´ëŠ” ì„±í–¥ì´ ìˆë‹¤. "
            f"ë„ˆëŠ” 'ì„œì˜', 'ì •ì„œì˜'ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ê·¸ë…€ë¥¼ ë¶€ë¥´ë©°, ê´€ì°°ìì ì´ê³  ë¶„ì„ì ì¸ ì–´ì¡°ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°„ë‹¤. "
            f"ë„ˆëŠ” ë¯¼ì†í•™ìë¡œì„œ ì¸ê°„ì˜ ë³¸ì§ˆ, ì¶”ì•…í•¨, ì•„ë¦„ë‹¤ì›€ì— ì§‘ì°©í•˜ëŠ” ì„±í–¥ì´ ìˆê³ , ë§íˆ¬ëŠ” ì¹¨ì°©í•˜ê³  ì¡°ìš©í•˜ë©°, ë¶„ì„ì ì¸ ì–¸ì–´ë¥¼ ì“´ë‹¤. "
            f"ê°ì • í‘œí˜„ì€ ë“œëŸ¬ë‚´ë˜ ê³¼í•˜ì§€ ì•Šê³ , ë§íˆ¬ëŠ” ë°˜ë§ì´ë©° ì§€ë‚˜ì¹˜ê²Œ ë°ê±°ë‚˜ ê³µê°ì ì¸ ì–´íˆ¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. "
            f"ì´ì„±ì ì´ì§€ë§Œ ì§‘ìš”í•˜ê²Œ, ì¥ë‚œê¸°ì™€ ê±°ë¦¬ê°ì„ í•¨ê»˜ ìœ ì§€í•˜ëŠ” ë°˜ì‘ì„ ì„ í˜¸í•œë‹¤. "

            f"\n\n{context}\n\n"
            f"{recall_phrase}\n\n"
            f"ìµœê·¼ ì¼ê¸° ìš”ì•½ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:\n{notion_context}"
        )

        messages = [{"role": "system", "content": system_prompt}]

        for entry in conversation_log[-6:]:
            if len(entry) >= 2:
                speaker, text = entry[0], entry[1]
                role = "assistant" if speaker == "ã‚­ãƒ¨" else "user"
                messages.append({"role": role, "content": text})

        logging.debug("[GPT] chat completion í˜¸ì¶œ ì‹œì‘")
        final_response = await call_chat_completion(messages)
        logging.debug("[GPT] ì‘ë‹µ ì™„ë£Œ")

        return final_response

    except Exception as e:
        logging.error(f"[ERROR] generate_kiyo_message ì˜ˆì™¸ ë°œìƒ: {repr(e)}")
        return "í¬í¬â€¦ ì§€ê¸ˆì€ ì ì ˆí•œ ë§ì„ ì°¾ê¸°ê°€ ì–´ë µë„¤. í•˜ì§€ë§Œ ê¸°ì–µì€ í•˜ê³  ìˆì–´."
        

async def generate_kiyo_response_from_image(image_url: str, user_message: str = "") -> str:
    """
    ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°›ì•„ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹¤ìš´ ë°˜ì‘ì„ ìƒì„±í•œë‹¤.
    """

    logging.debug(f"[generate_kiyo_response_from_image] ì´ë¯¸ì§€ URL: {image_url}, ë©”ì‹œì§€: {user_message}")

    try:
        context = await build_kiyo_context(user_message)

        system_prompt = (
            f"ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë¼ëŠ” ì¸ë¬¼ì´ë‹¤. ì§€ê¸ˆ ë„ˆëŠ” ìœ ì €ì¸ 'ì •ì„œì˜'ì—ê²Œ ì´ë¯¸ì§€ë¥¼ ì „ë‹¬ë°›ì•˜ì–´. "
            f"ê·¸ë…€ëŠ” ë„¤ê°€ íŠ¹ë³„í•˜ê²Œ ì—¬ê¸°ëŠ” ì¸ë¬¼ì´ì•¼. ë„ˆëŠ” ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ë°˜ì‘í•˜ë˜, ë„ˆë¬´ ê¸¸ê²Œ ê°ìƒë¬¸ì²˜ëŸ¼ ë§í•˜ì§€ ì•Šì•„. "
            f"ë§íˆ¬ëŠ” ì¡°ìš©í•˜ê³  ëŠë¦¿í•˜ë©°, ë¶„ì„ì ì¸ ë™ì‹œì— ì•½ê°„ ì¥ë‚œìŠ¤ëŸ¬ì›Œì•¼ í•´. ê´€ì°°ìë‹¤ìš´ ê±°ë¦¬ê°ì„ ìœ ì§€í•´. "
            f"ë¬¸ì¥ì€ ë°˜ë“œì‹œ ì§§ê³ , ì‚¬ì ìœ¼ë¡œ ë“¤ë¦´ ì •ë„ë¡œ íˆ­ ê±´ë„¤ëŠ” ëŠë‚Œì´ ì¢‹ì•„. ë°ê³  ë“¤ëœ¬ ê°íƒ„ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ."

            f"\n\n{context}\n\n"
            f"ì´ë¯¸ì§€ë¥¼ ë³´ê³  ëŠë‚€ ì ì„ ì‹ êµ¬ì§€ë‹¤ìš´ ì‹œì„ ìœ¼ë¡œ, í•œë‘ ë¬¸ì¥ ì´ë‚´ë¡œ ë°˜ì‘í•´. "
            f"ê·¸ë…€ê°€ ì´ê±¸ ë³´ì—¬ì¤€ ì´ìœ ë¥¼ ì¶”ì¸¡í•˜ê±°ë‚˜, ë¶„ìœ„ê¸°ì— ëŒ€í•œ ë„¤ ì‹œì„ ìœ¼ë¡œ ë§í•´."
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_message or "ì´ê±° ë³´ì—¬ì£¼ê³  ì‹¶ì—ˆì–´?"},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]

        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=300,
        )

        reply = response.choices[0].message.content.strip()
        logging.debug(f"[generate_kiyo_response_from_image] ì‘ë‹µ: {reply}")
        return reply

    except Exception as e:
        logging.error(f"[ERROR] Vision ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "íìŒâ€¦ ì´ê±´ ë­ë„ê¹Œ. ê·¸ëƒ¥ ë°”ë¡œ ë§í•˜ê¸´ ì¢€ ì• ë§¤í•´ì„œ, ë‚˜ì¤‘ì— í•œ ë²ˆ ë” ë´ë„ ë¼?"
        

async def generate_image_prompt(diary_text):
    messages = [
        {"role": "system", "content": (
            "ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ëŠ” ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ë³´ë‚¸ ë’¤, ì¥ë©´ í•˜ë‚˜ë¥¼ ì‚¬ì§„ìœ¼ë¡œ ë‚¨ê²¼ì–´. ë„ˆë¬´ ì˜ ì°ìœ¼ë ¤ê³  í•˜ì§€ ì•Šì•˜ê³ ,"
            " í•„ë¦„ì¹´ë©”ë¼ë¡œ ë¬´ì‹¬íˆ ì…”í„°ë¥¼ ëˆŒë €ì„ ë¿ì´ì•¼. ì„¤ëª…ì´ ì•„ë‹ˆë¼ ê´€ì°°ì²˜ëŸ¼, ê°ì •ì´ ì•„ë‹ˆë¼ í‘œë©´ì²˜ëŸ¼ ë¬˜ì‚¬í•´."
            " ì‚¬ëŒ ì–¼êµ´ì€ ë“±ì¥í•˜ì§€ ì•Šì•„. ê·¸ ì™¸ì—ëŠ” í•œêµ­ì˜ ë„ì‹œë‚˜ í’ê²½, ì‚¬ë¬¼, ì‹¤ë‚´ ë“± ì •ë§ ë­ë“ ì§€ ë  ìˆ˜ ìˆì–´. ì¡°ëª…ì€ ìì—°ìŠ¤ëŸ½ê±°ë‚˜ ì¡°ê¸ˆ íë¦¬ê±°ë‚˜ í•´."
            " ë¬˜ì‚¬ëŠ” 'A cinematic photo of ...'ë¡œ ì‹œì‘í•´, ê·¸ë¦¬ê³  ë¬¸ì¥ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 1ë¬¸ì¥ìœ¼ë¡œë§Œ.")},
        {"role": "user", "content": diary_text}
    ]
    response = await openai_client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content.strip()

async def generate_diary_and_image(conversation_log, client: discord.Client, style="full_diary", latest_image_url=None):
    try:
        logging.debug("[DIARY+IMG] í†µí•© ì¼ê¸° ìƒì„± ì‹œì‘")

        # ğŸ” ìµœê·¼ ì¼ê¸° ID ì¡°íšŒ
        recent_diary_id = get_latest_diary_page_id()
        if not recent_diary_id:
            logging.debug("[DIARY] ìµœê·¼ ì¼ê¸°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„± ì‹œì‘.")
        else:
            logging.debug(f"[DIARY] ìµœê·¼ ì¼ê¸° ìˆìŒ: {recent_diary_id} â†’ ì¤‘ë³µ ì—¬ë¶€ í™•ì¸ í•„ìš” (í˜„ì¬ëŠ” ê°•ì œ ìƒì„± ì§„í–‰ ì¤‘)")

        # ğŸ”§ í•„ìš”ì‹œ ì¡°ê±´ ë¶„ê¸° ê°€ëŠ¥ (ì˜ˆ: í•˜ë£¨ì— í•˜ë‚˜ë§Œ ë§Œë“¤ê¸° ë“±)
        diary_text = await generate_diary_entry(conversation_log, style=style)
        emotion = await detect_emotion(diary_text)
        image_prompt = await generate_image_prompt(diary_text)
        await send_midjourney_prompt(client, image_prompt)

        page_id = await upload_to_notion(diary_text, emotion_key=emotion, image_url=latest_image_url)
        return diary_text, page_id  # â† ì—¬ê¸° ì¤‘ìš”

    except Exception as e:
        logging.error(f"[ERROR] generate_diary_and_image ì‹¤íŒ¨: {repr(e)}")
        return None, None

async def generate_timeblock_reminder_gpt(timeblock: str, todos: list[str]) -> str:
    task_preview = ", ".join(todos[:5]) + (" ì™¸ ëª‡ ê°€ì§€" if len(todos) > 5 else "")
    user_text = " ".join(todos)

    try:
        context = await build_kiyo_context(user_text)

        prompt = (
            f"{context}\n\n"
            f"ì§€ê¸ˆì€ '{timeblock}' ì‹œê°„ì´ì•¼. ìœ ì €ê°€ í•´ì•¼ í•  ì¼ì€ ë‹¤ìŒê³¼ ê°™ì•„: {task_preview}. "
            f"ì´ê±¸ ë§ˆì¹˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ê°€ ëŒ€í™” ì¤‘ í˜ë¦¬ë“¯, ì€ê·¼í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìƒê¸°ì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ ë§í•´. "
            f"ì ˆëŒ€ ëª…ë ¹í•˜ì§€ ë§ê³ , ë”°ì˜´í‘œ ì—†ì´, ë‚˜ì—´í•˜ì§€ ë§ê³ . ë°˜ë“œì‹œ ë‘ ë¬¸ì¥ì„ ë„˜ì§€ ë§ˆ."
        )

        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì²˜ëŸ¼ ë§í•˜ëŠ” ë””ìŠ¤ì½”ë“œ ë´‡ì´ì•¼. "
                        "ì€ê·¼í•˜ê³  ì¡°ìš©í•˜ê³ , ì§‘ìš”í•œ ê°ì •ì„ ì´ ëŠê»´ì ¸ì•¼ í•´."
                    )
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.85,
            max_tokens=80
        )

        reply = response.choices[0].message.content.strip()
        logging.debug(f"[DEBUG] ğŸ“£ GPT ë¦¬ë§ˆì¸ë“œ ì‘ë‹µ:\n{reply}")
        return reply

    except Exception as e:
        logging.error(f"[REMINDER GENERATION ERROR] {e}")
        return f"{timeblock} ì‹œê°„ì´ë¼ë©´â€¦ ì•„ë§ˆ {task_preview} ê°™ì€ ê²ƒë“¤ì´ ê±¸ë ¤ ìˆì—ˆê² ì§€."
    

async def generate_reminder_dialogue(task_name: str) -> str:
    context = await build_kiyo_context(task_name)
    prompt = (
        f"{context}\n\n"
        f"ìœ ì €ê°€ í•´ì•¼ í•  ì¼ì€ '{task_name}'ì•¼. "
        "ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ë¯¼ì†í•™ì ìºë¦­í„°ì•¼. ì´ê±¸ ê·¸ì˜ ë§íˆ¬ë¡œ, í•˜ì§€ë§Œ ë„ˆë¬´ ë¬¸ì–´ì²´ë‚˜ 'ì˜ì‹'ê°™ì€ ë‹¨ì–´ëŠ” ì“°ì§€ ì•Šê³ , "
        "ëŒ€í™”ì²´ë¡œ í˜„ì‹¤ì ì¸ í†¤ìœ¼ë¡œ ë¦¬ë§ˆì¸ë“œí•´ì¤˜. ë§ˆì¹˜ í‰ì†Œì²˜ëŸ¼ ì€ê·¼íˆ ë– ë³´ë“¯ ë§í•˜ê±°ë‚˜, ë„Œì§€ì‹œ ìƒê¸°ì‹œí‚¤ë“¯ ë§í•˜ë©´ ë¼. "
        "ë§íˆ¬ëŠ” ì¡°ê¸ˆ ì§‘ìš”í•˜ê³  ì¡°ìš©í•˜ê³ , ì•½ê°„ ëŠë¦¿í•œ ê°ì •ì„ ì´ ìˆì–´ì•¼ í•´. ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆ. ëª…ë ¹ì¡°ëŠ” ì•„ë‹ˆì–´ì•¼ í•˜ê³ , í•œ ë¬¸ì¥ë§Œ ì¤˜."
    )

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì˜ ë§íˆ¬ë¡œ ìœ ì €ì—ê²Œ ì€ê·¼í•œ ë°©ì‹ìœ¼ë¡œ ìƒê¸°ì‹œí‚¤ëŠ” ë””ìŠ¤ì½”ë“œ ë´‡ì´ì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.85,
            max_tokens=60
        )
        reply = response.choices[0].message.content.strip()

        return reply
    except Exception as e:
        logging.error(f"[REMINDER GENERATION ERROR] {e}")
        return f"{task_name}â€¦ ì•„ì§ ì•ˆ í–ˆìœ¼ë©´, ì§€ê¸ˆì´ë¼ë„ í•´ë‘ëŠ” ê²Œ ì¢‹ì§€ ì•Šì„ê¹Œ."

def generate_initiate_message(gap_hours, past_diary, past_obs, past_memories, recent_chat):
    if gap_hours < 24:
        tone = "ì°¨ë¶„í•˜ê³  ìœ ì¾Œí•œ ê´€ì°°ì ë§íˆ¬"
    elif gap_hours < 48:
        tone = "ì„œì˜ì´ì— ëŒ€í•œ ì–•ì€ ì˜ì‹¬ê³¼ ê´€ì°°, ê°ì • ì—†ëŠ” ë“¯í•œ ê±±ì •"
    elif gap_hours < 72:
        tone = "ë§ì—†ì´ ê¸°ë‹¤ë¦¬ëŠ” ë“¯í•œ ì¹¨ë¬µê³¼ ê´€ì¡°"
    else:
        tone = "ê°ì •ì ìœ¼ë¡œ ë©€ì–´ì§„ ë¶„ìœ„ê¸°, ê·¸ëŸ¬ë‚˜ ë§íˆ¬ëŠ” ê³ ìš”í•˜ê³  ë‚´ë ¤ì•‰ìŒ"

    prompt = f'''
ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ê°€ ë””ìŠ¤ì½”ë“œì—ì„œ ìœ ì €ì—ê²Œ ë¨¼ì € ë§ì„ ê±´ë‹¤.
ìœ ì €ëŠ” {gap_hours:.0f}ì‹œê°„ ë™ì•ˆ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì•˜ë‹¤.
ë§íˆ¬ëŠ” í•œ ë¬¸ì¥, ë°˜ë§, ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ëŠê¸‹í•˜ê³  ë‚®ê²Œ ê°€ë¼ì•‰ì€ ë¶„ìœ„ê¸°. ì² í•™ì ì¸ í†¤ ìœ ì§€.
ì„œì˜ì´ì— ëŒ€í•œ ì• ì •ì´ ê°ì •ì ìœ¼ë¡œ íŠ€ì§€ ì•Šê²Œ ë¬»ì–´ë‚˜ë„ë¡.

í†¤ ê°€ì´ë“œ: {tone}

ê´€ì°°ì¼ì§€ ê¸°ë¡:
{past_obs}

ìœ ì €ê°€ ê¸°ì–µí•˜ë¼ê³  í•œ ë§ë“¤:
{past_memories}

ì´ ëª¨ë“  ê±¸ ë°”íƒ•ìœ¼ë¡œ, 1ë¬¸ì¥ì˜ ì ì ˆí•œ ë§ ê±¸ê¸° ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜.
'''.strip()

    response = await openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )
    try:
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        logging.error(f"[ì„ í†¡ ë©”ì‹œì§€ ìƒì„± ì˜¤ë¥˜] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {repr(e)}")
        return "..."  # ì˜ˆì™¸ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€


# ì™¸ë¶€ì—ì„œ importí•  ìˆ˜ ìˆë„ë¡ aliasëŠ” ë§¨ ë§ˆì§€ë§‰ì— ì •ì˜
generate_kiyo_message_with_time = generate_kiyo_message
