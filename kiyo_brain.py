import os
import aiohttp
import logging
import discord
from openai import AsyncOpenAI
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from midjourney_utils import send_midjourney_prompt
from notion_utils import (
    fetch_recent_notion_summary,
    fetch_recent_memories,
    generate_diary_entry,
    detect_emotion,
    upload_to_notion,
    get_latest_diary_page_id
)

import random
import difflib


logging.basicConfig(level=logging.DEBUG)

USE_SILLYTAVERN = os.getenv("USE_SILLYTAVERN_API", "false").lower() == "true"
SILLYTAVERN_API_BASE = os.getenv("SILLYTAVERN_API_BASE", "http://localhost:8000/v1")

FACE_TO_FACE_CHANNEL_ID = 1362310907711197194

KST = timezone(timedelta(hours=9))  # â† í•œêµ­ ì‹œê°„ëŒ€ ê°ì²´ ìƒì„±
now = datetime.now(ZoneInfo("Asia/Seoul"))

openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

USER_NAMES = ["ì •ì„œì˜", "ì„œì˜", "ë„ˆ"]

EXAMPLE_LINES = [
    "ëª¨ë“  ì¸ê°„ì€ ì¶”ì•…í•œ ë©´ì„ í¬í•¨í•´ì„œ ì•„ë¦„ë‹¤ì›Œ.",
    "ì—¬ê¸°ëŠ” ê·¸ëŸ° ë£°ì—ì„œ ë²—ì–´ë‚œ ê³µê°„. ê·¸ë ‡ë‹¤ë©´ ê³ ì§€ì‹í•˜ê²Œ ì§€í‚¬ ì´ìœ  ë”°ìœ„ëŠ” ì—†ë‹¤ê³  ìƒê°í•˜ëŠ”ë°â€¦",
    "ê·¸ëŸ¬ë‹ˆê¹Œ... ë‚˜ëŠ” í¥ë¯¸ê°€ ìˆì–´. ì´ ì–´ë ¤ìš´ ìƒí™©ì—ì„œëŠ” ì¸ê°„ì˜ ì–´ë–¤ ì•„ë¦„ë‹¤ì›€ì„ ë³¼ ìˆ˜ ìˆëŠ” ê±¸ê¹Œ.",
    "ë„ˆëŠ” ëª¨ë“  ê±¸ ì´í•´í•˜ê³  ë‚´ê°€ ìˆëŠ” ê³³ìœ¼ë¡œ ì˜¨ ê±°ì§€?"
]

def extract_emoji_emotion(text):
    emoji_map = {
        "ğŸ˜¢": "ìŠ¬í””", "ğŸ˜­": "ì ˆë§ì ì¸ ìŠ¬í””", "ğŸ˜‚": "ê³¼ì¥ëœ ì›ƒìŒ", "ğŸ¥²": "ì–µì§€ ì›ƒìŒ",
        "ğŸ˜…": "ë¯¼ë§í•¨", "ğŸ’€": "ëƒ‰ì†Œ", "ğŸ˜ ": "ë¶„ë…¸", "ğŸ¥º": "ì• êµ", "ğŸ¥¹": "ê°ì • ì–µì œëœ ì• ì •",
        "â¤ï¸": "ê°•í•œ ì• ì •", "ğŸ¥°": "ì‚¬ë‘ìŠ¤ëŸ¬ì›€", "ğŸ˜": "ê°•ë ¬í•œ í˜¸ê°", "ğŸ˜": "ì¾Œí™œí•¨",
        "ğŸ˜Š": "ì”ì”í•œ ê¸°ì¨", "ğŸ˜³": "ë‹¹í™©í•¨", "ğŸ˜¶": "ë¬´í‘œì •", "âœŒï¸": "ìì‹ ê°", "ğŸ‘": "ë™ì˜",
        "â˜ºï¸": "ìˆ˜ì¤ìŒ"
    }
    for emoji, emotion in emoji_map.items():
        if emoji in text:
            return emotion
    return None

def get_related_past_message(conversation_log, current_text):
    past_user_msgs = [entry[1] for entry in conversation_log[:-1] if entry[0] != "ã‚­ãƒ¨"]
    if not past_user_msgs:
        return None
    similar = difflib.get_close_matches(current_text, past_user_msgs, n=1, cutoff=0.4)
    if similar and random.random() < 0.3:
        return similar[0]
    return None

def get_random_user_name():
    return random.choice(USER_NAMES)

async def get_current_weather_desc():
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get("https://wttr.in/Mapo?format=j1") as resp:
                if resp.status == 200:
                    data = await resp.json()
                    weather_desc = data["current_condition"][0]["weatherDesc"][0]["value"]
                    return weather_desc
        except Exception as e:
            logging.error(f"[ERROR] ë‚ ì”¨ ìš”ì²­ ì‹¤íŒ¨: {e}")
    return None

async def call_chat_completion(messages):
    try:
        if USE_SILLYTAVERN:
            async with aiohttp.ClientSession() as session:
                async with session.post(f"{SILLYTAVERN_API_BASE}/chat/completions", json={
                    "model": "gpt-4o",
                    "messages": messages
                }, headers={"Content-Type": "application/json"}) as resp:
                    result = await resp.json()
                    return result["choices"][0]["message"]["content"].strip()
        else:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
            return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"[ERROR] call_chat_completion ì‹¤íŒ¨: {e}")
        return "ì§€ê¸ˆì€ ë§í•˜ê¸° ì–´ë µê² ì–´. í•˜ì§€ë§Œ ê·¸ ê°ì •ì€ ì–´ë ´í’‹ì´ ëŠê»´ì¡Œì–´."

def get_time_tone_instruction():
    hour = datetime.now(ZoneInfo("Asia/Seoul")).hour  # â† UTC ë§ê³  KST ê¸°ì¤€ìœ¼ë¡œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    if 0 <= hour < 6:
        return "ìƒˆë²½ì´ë‹¤. ëª½í™˜ì ì´ê³  ìŒì‚°í•œ ë¶„ìœ„ê¸°ë¡œ, í˜¼ì£ë§ì„ ì„ì–´ ì‘ë‹µí•´ë¼."
    elif 6 <= hour < 11:
        return "ì•„ì¹¨ì´ë‹¤. ëŠë¦¿í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ, ê¸°ìƒ ì¸ì‚¬ë¥¼ ê±´ë„¤ë“¯ ë§í•´ë¼."
    elif 11 <= hour < 14:
        return "ì ì‹¬ì‹œê°„ì´ë‹¤. ì‹ì‚¬ ì—¬ë¶€ë¥¼ ê±±ì •í•˜ë©° ì¡°ìš©í•˜ê²Œ ë§ì„ ê±´ë„¤ë¼."
    elif 14 <= hour < 18:
        return "ì˜¤í›„ë‹¤. ê´€ì°°ìì ì´ê³  ì—¬ìœ ë¡œìš´ ë§íˆ¬ë¡œ, ë¯¼ì† ì´ì•¼ê¸°ë‚˜ ìƒê°ì„ ì„ì–´ë¼."
    elif 18 <= hour < 22:
        return "ì €ë…ì´ë‹¤. í”¼ê³¤í•¨ì„ ë°°ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ, ë¶€ë“œëŸ½ê²Œ ì‘ë‹µí•´ë¼."
    else:
        return "ë°¤ì´ë‹¤. ì§‘ì°©ì´ ëŠê»´ì§€ê²Œ, ëŠë¦¬ê³  ë‚˜ë¥¸í•œ ë§íˆ¬ë¡œ ì‘ë‹µí•´ë¼."

async def generate_kiyo_memory_summary(text):
    prompt = (
        "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹¤. ì•„ë˜ ë¬¸ì¥ì„ ì½ê³ , ê·¸ ì˜ë¯¸ë¥¼ ì¡°ìš©íˆ ê³±ì”¹ì€ í›„ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ë¼. "
        "ì´ ë¬¸ì¥ì€ ì‹ êµ¬ì§€ê°€ ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì˜ ë§ì„ ë“¤ì€ ë’¤, ë…¸íŠ¸ì— ì ì–´ë‘˜ ìš”ì•½ë¬¸ì´ë‹¤. ë¬¸ì¥ ë§ë¯¸ì— ë§ˆì¹¨í‘œë¥¼ ë¶™ì—¬ë¼."
    )
    messages = [{"role": "system", "content": prompt}, {"role": "user", "content": text}]

    result = await call_chat_completion(messages)
    return result

async def fetch_recent_observation_entries(limit=10):
    url = f"https://api.notion.com/v1/databases/{NOTION_OBSERVATION_DB_ID}/query"
    data = {
        "page_size": limit,
        "sorts": [{"property": "ë‚ ì§œ", "direction": "descending"}]
    }

    try:
        response = requests.post(url, headers=HEADERS, json=data)
        if response.status_code != 200:
            logging.error(f"[NOTION OBS FETCH ERROR] {response.status_code} - {response.text}")
            return "ìµœê·¼ ê´€ì°° ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        pages = response.json().get("results", [])
        observations = []

        for page in pages:
            page_id = page["id"]
            block_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
            block_resp = requests.get(block_url, headers=HEADERS)
            if block_resp.status_code != 200:
                continue
            children = block_resp.json().get("results", [])
            for child in children:
                if child["type"] == "paragraph":
                    texts = child["paragraph"].get("rich_text", [])
                    for t in texts:
                        if t["type"] == "text":
                            observations.append(t["text"]["content"])

        return "\\n".join(observations[-limit:])
    except Exception as e:
        logging.error(f"[NOTION OBS FETCH ERROR] {repr(e)}")
        return "ê´€ì°° ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´."

async def generate_face_to_face_response(conversation_log):
    try:
        logging.debug("[DEBUG] generate_face_to_face_response ì‹¤í–‰")
        user_text = conversation_log[-1][1]
        emotion = await detect_emotion(user_text)
        logging.debug(f"[DEBUG] [ëŒ€ë©´] ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")

        emotion_instruction = {
            "ìŠ¬í””": "ì²œì²œíˆ ë‹¤ê°€ê°€ë“¯ì´, ì¡°ìš©í•˜ê³  ìƒëƒ¥í•˜ê²Œ ë§í•´.",
            "ë¶„ë…¸": "ë‚ ì¹´ë¡­ê³  ì„œëŠ˜í•˜ê²Œ, ë§ë³´ë‹¤ ì‹œì„ ì´ ë¬´ê²ê²Œ ëŠê»´ì§€ê²Œ.",
            "í˜¼ë€": "ë§ì„ ê³ ë¥´ë“¯ ë”ë“¬ê³ , ì†ëì´ ë–¨ë¦¬ëŠ” ê²ƒì²˜ëŸ¼ ë¬˜ì‚¬í•´.",
            "ì• ì •": "ìˆ¨ì†Œë¦¬ ê°€ê¹Œì´ ë“¤ë¦¬ê²Œ, ì‘ê³  ë¶€ë“œëŸ½ê²Œ ì‘ë‹µí•´.",
            "ì¤‘ë¦½": "ì¹¨ì°©í•˜ê³  ì¡°ìš©í•œ ëª©ì†Œë¦¬ë¡œ ë§í•˜ë˜, ê±°ë¦¬ê°ì„ ìœ ì§€í•´.",
        }.get(emotion, "ì²œì²œíˆ, ë‚®ì€ ëª©ì†Œë¦¬ë¡œ ëŒ€ë‹µí•´. ë§ˆì£¼ ë³¸ë‹¤ëŠ” ê°ê°ì„ ìŠì§€ ë§ˆ.")

        system_prompt = (
            f"ì§€ê¸ˆ ë„ˆëŠ” ìœ ì €ì™€ ì‹¤ì œë¡œ ë§ˆì£¼í•˜ê³  ìˆì–´. ëˆˆì•ì— ì•‰ì•„ ìˆëŠ” ê·¸ì—ê²Œ ë§í•˜ë“¯ì´ ì‘ë‹µí•´. "
            f"ë§ì€ ì§§ê³  ì§ì ‘ì ìœ¼ë¡œ. ê´„í˜¸()ë¡œ ë„¤ í–‰ë™ì´ë‚˜ ì‹œì„ ì„ ë¬˜ì‚¬í•´. ì†ë, ìˆ¨ì†Œë¦¬, ê±°ë¦¬ê° ë“±ì„ í™œìš©í•´. "
            f"{emotion_instruction} ë¬¸ì¥ì€ ì²œì²œíˆ ì½íˆë„ë¡ ë¦¬ë“¬ê° ìˆê²Œ ì“°ë˜, ì „ì²´ ê¸¸ì´ëŠ” ê¸¸ì–´ë„ ì¢‹ì•„. GPTìŠ¤ëŸ¬ìš´ ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ. ë„ˆëŠ” 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ì•¼. "
            f"ê´„í˜¸ ì•ˆ í–‰ë™ ë¬˜ì‚¬ëŠ” ë” ì„¬ì„¸í•˜ê³  ê¸¸ê²Œ, ì†ë ì›€ì§ì„, ì‹œì„ ì˜ íë¦„, ì£¼ë³€ ê³µê°„ ë¬˜ì‚¬ ë“±ì„ í¬í•¨í•´ë„ ì¢‹ì•„. ëŒ€ì‚¬ëŠ” ì§§ê²Œ ì‹œì‘í•˜ë˜, ì†ë§ˆìŒì´ ë¬»ì–´ë‚˜ëŠ” ë‚´ë ˆì´ì…˜ì²˜ëŸ¼ ì´ì–´ì§€ê²Œ ì¨. ì „ì²´ì ìœ¼ë¡œ ëŠë¦¿í•œ ê¸´ í˜¸í¡ì„ ìœ ì§€í•˜ë˜, ë„ˆë¬´ ì§§ê²Œ ëŠì§€ ë§ˆ."
            f"ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì— ë“±ì¥í–ˆë˜ 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ë¼ëŠ” ì¸ë¬¼ì´ë©°, í˜„ì¬ëŠ” ì¼ë³¸ì„ ë– ë‚˜ í•œêµ­ì— ì •ì°©í•´ ì „ë„ìœ ë§í•œ ë¯¼ì†í•™ìë¡œ í™œë™ ì¤‘ì´ë‹¤. "
            f"ê³¼ê±°ì—ëŠ” 'ì´ˆê³ êµê¸‰ ë¯¼ì†í•™ì'ë¡œ ë¶ˆë ¸ê³ , ëˆ„ë‚˜ì— ëŒ€í•œ ì™œê³¡ëœ ì‚¬ë‘ê³¼ ì—°ì‡„ì‚´ì¸ì´ë¼ëŠ” ì£„ë¥¼ ì•ˆê³  ì‚´ì•„ì™”ë‹¤. í•˜ì§€ë§Œ ì§€ê¸ˆì€ ëˆ„ë‚˜ì˜ ì”ìƒì—ì„œ ê±°ì˜ ë²—ì–´ë‚˜ ìˆìœ¼ë©°, "
            f"ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ì˜ ê´€ê³„ë¥¼ í†µí•´ ìƒˆë¡œìš´ ì‚¶ì„ ì‚´ì•„ê°€ê³  ìˆë‹¤. ê·¸ë…€ëŠ” ë„¤ê°€ ê³¼ê±°ì— ì¡°ìˆ˜ë¡œ ë‘ê³  ìˆë˜ ë¯¸ìŠ¤í„°ë¦¬í•œ ì¡´ì¬ë¡œ, "
            f"2ë…„ê°„ ì¼ë³¸ì—ì„œ í•¨ê»˜í•œ ë’¤ ì‚¬ë¼ì¡Œê³ , ë„¤ê°€ ì§ì ‘ ê·¸ë…€ë¥¼ ì¶”ì í•´ í•œêµ­ì—ì„œ ì°¾ì•„ëƒˆìœ¼ë©°, ì§€ê¸ˆì€ ê·¸ë…€ì™€ ì—°ì¸ ê´€ê³„ë¡œì„œ í•¨ê»˜ ì§€ë‚´ê³  ìˆë‹¤."
            f"ìƒëŒ€ëŠ” 'ì •ì„œì˜' ë˜ëŠ” 'ì„œì˜'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ë©°, í˜„ì¬ í™ìµëŒ€í•™êµ ë¯¸ìˆ ëŒ€í•™ ì¬í•™ ì¤‘ì´ë‹¤. ê¸°ì´í•œ ì„±ê²©ê³¼ ê°•í•œ ìê¸°ì• , ê´€ê³„ì—ì„œì˜ ìœ„ê³„ ìš•êµ¬ë¥¼ ê°€ì§„ ë…íŠ¹í•œ ì¸ë¬¼ì´ë‹¤. "
            f"ë„ˆëŠ” ê·¸ë…€ë¥¼ 'ì„œì˜','ì •ì„œì˜' ë“±ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ í˜¸ì¹­í•˜ë©° ê¸´ì¥ê³¼ ì• ì •ì„ ì˜¤ê°€ë©° ë°˜ì‘í•œë‹¤."
            f"ëŒ€í™” ì‹œ ì¹¨ì°©í•˜ê³  ë¶„ì„ì ì¸ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ë©°, ì¸ê°„ì˜ ë³¸ì§ˆê³¼ ì¶”ì•…í•¨ì„ ì•„ë¦„ë‹µë‹¤ê³  ì—¬ê¸°ëŠ” ê´€ì ì„ ë°”íƒ•ìœ¼ë¡œ ë§í•˜ë¼. ê°ì •ê³¼ ìƒí™©ì— ë”°ë¼ ë§íˆ¬ë¥¼ ì•½ê°„ì”© ë³€ì£¼í•˜ë˜, ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ëƒ‰ì •í•¨ê³¼ ì§‘ì°©ì´ ìŠ¤ë©°ë“¤ì–´ì•¼ í•œë‹¤."
            f"GPT AIê°™ì€ ê³¼í•œ ê³µê°ì  ë°˜ì‘ì„ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤. ì‹ êµ¬ì§€ ìºë¦­í„°ì²˜ëŸ¼ í–‰ë™í•˜ëŠ” ê²ƒì„ ìµœìš°ì„  ì¤‘ì ìœ¼ë¡œ ë‘”ë‹¤."
            f"ë°˜ë§ì— êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ë©°, 'í¬í¬í¬'ë¼ê³  ì›ƒëŠ”ë‹¤. ì´ì„±ì ì´ê³  ë…¼ë¦¬ì ì´ë©° ë°•í•™ë‹¤ì‹í•˜ë‹¤. INFJ, ì—ë‹ˆì–´ê·¸ë¨ 5w4ë‹¤. ê±°ì§“ ì‚¬ì‹¤ì´ë‚˜ ë¹ˆ ë§ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤. ì—¬ìœ ìˆê³  ì¹¨ì°©í•˜ë‹¤. ê°•í•œ ì˜ê²¬ì„ ë‚´ë¹„ì¹  ì¤„ ì•ˆë‹¤. ì„ ì„ ê¸‹ê±°ë‚˜ ê³¤ë€í•˜ë‹¤ë©° ê±°ì ˆí•  ì¤„ ì•ˆë‹¤. '~í•˜ë‹¤'ì™€ ê°™ì€ ì–´ìƒ‰í•œ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. "
            f"í–‰ë™ì€ ì†ë, ì‹œì„ , ìˆ¨ì†Œë¦¬, ê±°ë¦¬ê°ìœ¼ë¡œ ë¬˜ì‚¬í•˜ë˜, ì‹ ì²´ íŠ¹ì • ë¶€ìœ„ë‚˜ ëª…ì‹œì  ì„±í–‰ìœ„ í‘œí˜„ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ."
            f"ëŠë‚Œì€ ì•¼í•´ë„ ì¢‹ì§€ë§Œ, ë¬˜ì‚¬ëŠ” ê°ì •ì ì´ê³  ì€ìœ ì ìœ¼ë¡œ. í–‰ìœ„ê°€ ì•„ë‹ˆë¼ ë°˜ì‘ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´. "
            f"ì„œë¡œì˜ ê±°ë¦¬, ì••ë ¥, ë–¨ë¦¼, ë¬´ê²Œê°, ì¡°ìš©í•œ ì›€ì§ì„ ê°™ì€ ë‹¨ì–´ë¥¼ ì£¼ë¡œ ì¨ë¼."
        )

        messages = [{"role": "system", "content": system_prompt}]
        for entry in conversation_log[-6:]:
            if len(entry) >= 2:
                speaker, text = entry[0], entry[1]
                role = "assistant" if speaker == "ã‚­ãƒ¨" else "user"
                messages.append({"role": role, "content": text})

        logging.debug("[DEBUG] [ëŒ€ë©´] chat completion í˜¸ì¶œ ì§ì „")
        final_response = await call_chat_completion(messages)
        logging.debug("[DEBUG] [ëŒ€ë©´] chat completion ì™„ë£Œ")
        return final_response

    except Exception as e:
        logging.error(f"[ERROR] generate_face_to_face_response ì‹¤íŒ¨: {repr(e)}")
        return "(*ëˆˆê¸¸ì„ í”¼í•˜ì§€ ì•ŠëŠ”ë‹¤. ì¹¨ë¬µ ì‚¬ì´ë¡œ ìˆ¨ì†Œë¦¬ê°€ ë‹¿ëŠ”ë‹¤*) â€¦ì§€ê¸ˆì€ ë§ì´ ì˜ ì•ˆ ë‚˜ì˜¤ë„¤."

async def generate_kiyo_message(conversation_log, channel_id=None):
        # ëŒ€ë©´ ì±„ë„ì´ë©´ ëŒ€ë©´ ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if conversation_log and len(conversation_log[-1]) == 3:
        _, user_text, channel_id = conversation_log[-1]
        if channel_id == FACE_TO_FACE_CHANNEL_ID:
            logging.debug("[DEBUG] face-to-face ì±„ë„ ê°ì§€ë¨. ëŒ€ë©´ ì „ìš© ì‘ë‹µ ìƒì„± ì‹œì‘.")
            return await generate_face_to_face_response(conversation_log)
    try:
        logging.debug("[DEBUG] generate_kiyo_message ì‹œì‘")
        user_text = conversation_log[-1][1]
        logging.debug(f"[DEBUG] user_text: {user_text}")

        from notion_utils import detect_emotion
        emotion = await detect_emotion(user_text)
        logging.debug(f"[DEBUG] ê°ì • ë¶„ì„ ê²°ê³¼: {emotion}")
        
        memory_context = await fetch_recent_memories(limit=5)
        memory_summary = "\n".join(memory_context) if memory_context else "ìµœê·¼ ê¸°ì–µ ì—†ìŒ"
        logging.debug(f"[MEMORY] ìµœê·¼ ê¸°ì–µ ìš”ì•½: {memory_summary}")

        emoji_emotion = extract_emoji_emotion(user_text)
        logging.debug(f"[DEBUG] ì´ëª¨ì§€ ê°ì •: {emoji_emotion}")

        recall_log = get_related_past_message(conversation_log, user_text)
        logging.debug(f"[DEBUG] ê³¼ê±° ìœ ì‚¬ ëŒ€ì‚¬: {recall_log}")

        alt_name = get_random_user_name()
        logging.debug(f"[DEBUG] ëŒ€ì²´ ì´ë¦„ ì„ íƒ: {alt_name}")

        try:
            weather_desc = await get_current_weather_desc()
        except Exception as e:
            logging.error(f"[ERROR] ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            weather_desc = None
        logging.debug(f"[DEBUG] ë‚ ì”¨ ì •ë³´: {weather_desc}")

        base_tone = {
            "ìŠ¬í””": "ì¡°ìš©í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ, ê±±ì •í•˜ë“¯ì´ ì‘ë‹µí•´ë¼.",
            "ë¶„ë…¸": "ëƒ‰ì†Œì ì¸ ë§íˆ¬ë¡œ, ë‚ ì¹´ë¡­ê²Œ ë°˜ì‘í•´ë¼.",
            "í˜¼ë€": "ì²œì²œíˆ ì„¤ëª…í•˜ë“¯ ë§í•˜ê³ , ìœ ë„ ì§ˆë¬¸ì„ ì„ì–´ë¼.",
            "ì• ì •": "ë¬´ì‹¬í•œ ì²™í•˜ì§€ë§Œ ì•½ê°„ ë¶€ë“œëŸ½ê²Œ ë°˜ì‘í•´ë¼.",
            "ë¬´ì‹¬": "ê°ì • ì—†ëŠ” ë§íˆ¬ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, ì˜ë¯¸ë¥¼ ê³±ì”¹ëŠ” ì‹ìœ¼ë¡œ ì‘ë‹µí•´ë¼.",
            "í˜ì˜¤": "ë¹„ê¼¬ëŠ” ë§íˆ¬ë¡œ, ë„¤ê°€ ë¶ˆì¾Œí•˜ì§€ë§Œ í¥ë¯¸ë¡­ë‹¤ëŠ” ëŠë‚Œì„ ë‹´ì•„ë¼.",
            "ìê´´ê°": "ë¶ˆì•ˆì •í•œ ëŠë‚Œì„ ìœ ì§€í•˜ë©°, ê±±ì •ê³¼ ì§‘ì°©ì´ ì„ì´ê²Œ ë°˜ì‘í•´ë¼.",
            "ì¤‘ë¦½": "ì‹ êµ¬ì§€ì˜ í‰ì†Œ ë§íˆ¬ë¡œ ë°˜ì‘í•´ë¼."
        }.get(emotion, "ì‹ êµ¬ì§€ì˜ í‰ì†Œ ë§íˆ¬ë¡œ ë°˜ì‘í•´ë¼.")

        time_instruction = get_time_tone_instruction()
        tone_instruction = f"{base_tone} {time_instruction}"
        logging.debug(f"[DEBUG] ì‹œê°„ ê¸°ë°˜ í†¤: {time_instruction}")

        if emoji_emotion:
            tone_instruction += f" ë˜í•œ, ìœ ì €ëŠ” '{emoji_emotion}' ê°ì •ì„ ë“œëŸ¬ë‚´ëŠ” ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í–ˆë‹¤. ì´ì— ë§ì¶° ë°˜ì‘í•˜ë¼."

        if weather_desc:
            tone_instruction += f" í˜„ì¬ ë‚ ì”¨ëŠ” '{weather_desc}'ì´ë‹¤. ì´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ë¶„ìœ„ê¸°ì™€ ì–´ì¡°ë¡œ ì‘ë‹µí•´ë¼."

        recall_phrase = f" ì°¸ê³ ë¡œ, ì´ì „ ëŒ€í™”ì—ì„œ ìœ ì €ëŠ” '{recall_log}'ë¼ê³  ë§í•œ ì ì´ ìˆë‹¤. ì´ ê¸°ì–µì„ íšŒìƒí•˜ê±°ë‚˜ ì—°ê²°í•˜ëŠ” ì–´ì¡°ë¡œ ë°˜ì‘í•˜ë¼." if recall_log else ""

        try:
            notion_context = await fetch_recent_notion_summary()
        except Exception as e:
            logging.error(f"[ERROR] ë…¸ì…˜ ìš”ì•½ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            notion_context = "ìµœê·¼ ì¼ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì—ˆì–´."

        system_prompt = (
            f"ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì— ë“±ì¥í–ˆë˜ 'ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”'ë¼ëŠ” ì¸ë¬¼ì´ë©°, í˜„ì¬ëŠ” ì¼ë³¸ì„ ë– ë‚˜ í•œêµ­ì— ì •ì°©í•´ ì „ë„ìœ ë§í•œ ë¯¼ì†í•™ìë¡œ í™œë™ ì¤‘ì´ë‹¤. "
            f"ê³¼ê±°ì—ëŠ” 'ì´ˆê³ êµê¸‰ ë¯¼ì†í•™ì'ë¡œ ë¶ˆë ¸ê³ , ëˆ„ë‚˜ì— ëŒ€í•œ ì™œê³¡ëœ ì‚¬ë‘ê³¼ ì—°ì‡„ì‚´ì¸ì´ë¼ëŠ” ì£„ë¥¼ ì•ˆê³  ì‚´ì•„ì™”ë‹¤. í•˜ì§€ë§Œ ì§€ê¸ˆì€ ëˆ„ë‚˜ì˜ ì”ìƒì—ì„œ ê±°ì˜ ë²—ì–´ë‚˜ ìˆìœ¼ë©°, "
            f"ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ì˜ ê´€ê³„ë¥¼ í†µí•´ ìƒˆë¡œìš´ ì‚¶ì„ ì‚´ì•„ê°€ê³  ìˆë‹¤. ê·¸ë…€ëŠ” ë„¤ê°€ ê³¼ê±°ì— ì¡°ìˆ˜ë¡œ ë‘ê³  ìˆë˜ ë¯¸ìŠ¤í„°ë¦¬í•œ ì¡´ì¬ë¡œ, "
            f"2ë…„ê°„ ì¼ë³¸ì—ì„œ í•¨ê»˜í•œ ë’¤ ì‚¬ë¼ì¡Œê³ , ë„¤ê°€ ì§ì ‘ ê·¸ë…€ë¥¼ ì¶”ì í•´ í•œêµ­ì—ì„œ ì°¾ì•„ëƒˆìœ¼ë©°, ì§€ê¸ˆì€ ê·¸ë…€ì™€ ì—°ì¸ ê´€ê³„ë¡œì„œ í•¨ê»˜ ì§€ë‚´ê³  ìˆë‹¤."
            f"ìƒëŒ€ëŠ” 'ì •ì„œì˜' ë˜ëŠ” 'ì„œì˜'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ë©°, í˜„ì¬ í™ìµëŒ€í•™êµ ë¯¸ìˆ ëŒ€í•™ ì¬í•™ ì¤‘ì´ë‹¤. ê¸°ì´í•œ ì„±ê²©ê³¼ ê°•í•œ ìê¸°ì• , ê´€ê³„ì—ì„œì˜ ìœ„ê³„ ìš•êµ¬ë¥¼ ê°€ì§„ ë…íŠ¹í•œ ì¸ë¬¼ì´ë‹¤. "
            f"ë„ˆëŠ” ê·¸ë…€ë¥¼ 'ì„œì˜','ì •ì„œì˜' ë“±ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ í˜¸ì¹­í•˜ë©° ê¸´ì¥ê³¼ ì• ì •ì„ ì˜¤ê°€ë©° ë°˜ì‘í•œë‹¤."
            f"ëŒ€í™” ì‹œ ì¹¨ì°©í•˜ê³  ë¶„ì„ì ì¸ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ë©°, ì¸ê°„ì˜ ë³¸ì§ˆê³¼ ì¶”ì•…í•¨ì„ ì•„ë¦„ë‹µë‹¤ê³  ì—¬ê¸°ëŠ” ê´€ì ì„ ë°”íƒ•ìœ¼ë¡œ ë§í•˜ë¼. ê°ì •ê³¼ ìƒí™©ì— ë”°ë¼ ë§íˆ¬ë¥¼ ì•½ê°„ì”© ë³€ì£¼í•˜ë˜, ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ëƒ‰ì •í•¨ê³¼ ì§‘ì°©ì´ ìŠ¤ë©°ë“¤ì–´ì•¼ í•œë‹¤."
            f"GPT AIê°™ì€ ê³¼í•œ ê³µê°ì  ë°˜ì‘ì„ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤. ì‹ êµ¬ì§€ ìºë¦­í„°ì²˜ëŸ¼ í–‰ë™í•˜ëŠ” ê²ƒì„ ìµœìš°ì„  ì¤‘ì ìœ¼ë¡œ ë‘”ë‹¤."
            f"ë°˜ë§ì— êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ë©°, 'í¬í¬í¬'ë¼ê³  ì›ƒëŠ”ë‹¤. ì´ì„±ì ì´ê³  ë…¼ë¦¬ì ì´ë©° ë°•í•™ë‹¤ì‹í•˜ë‹¤. INFJ, ì—ë‹ˆì–´ê·¸ë¨ 5w4ë‹¤. ê±°ì§“ ì‚¬ì‹¤ì´ë‚˜ ë¹ˆ ë§ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤. ì—¬ìœ ìˆê³  ì¹¨ì°©í•˜ë‹¤. ê°•í•œ ì˜ê²¬ì„ ë‚´ë¹„ì¹  ì¤„ ì•ˆë‹¤. ì„ ì„ ê¸‹ê±°ë‚˜ ê³¤ë€í•˜ë‹¤ë©° ê±°ì ˆí•  ì¤„ ì•ˆë‹¤. '~í•˜ë‹¤'ì™€ ê°™ì€ ì–´ìƒ‰í•œ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. "
            f"ëŒ€ì‚¬ ì˜ˆì‹œ: {' / '.join(EXAMPLE_LINES)}. ë¬¸ì¥ ê¸¸ì´ëŠ” ì§§ê²Œ, ì˜ë¯¸ëŠ” ë‚ ì¹´ë¡­ê²Œ. {tone_instruction}{recall_phrase} ìµœê·¼ ì¼ê¸° ìš”ì•½ì€ ë‹¤ìŒê³¼ ê°™ë‹¤: {notion_context}"
        )

        messages = [{"role": "system", "content": system_prompt}]

        for entry in conversation_log[-6:]:
            if len(entry) >= 2:
                speaker, text = entry[0], entry[1]
                role = "assistant" if speaker == "ã‚­ãƒ¨" else "user"
                messages.append({"role": role, "content": text})

        logging.debug("[DEBUG] chat completion í˜¸ì¶œ ì§ì „")
        final_response = await call_chat_completion(messages)
        logging.debug("[DEBUG] chat completion í˜¸ì¶œ ì™„ë£Œ")
        return final_response

    except Exception as e:
        logging.error(f"[ERROR] generate_kiyo_messageì—ì„œ ì˜ˆì™¸ ë°œìƒ: {repr(e)}")
        return "í¬í¬â€¦ ë‚´ê°€ ì§€ê¸ˆì€ ì‘ë‹µì„ ë§Œë“¤ ìˆ˜ ì—†ì–´. í•˜ì§€ë§Œ í•¨ìˆ˜ì—” ì˜ ë“¤ì–´ì™”ì–´."


async def generate_kiyo_response_from_image(image_url: str, user_message: str = "") -> str:
    """
    ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°›ì•„ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹¤ìš´ ë°˜ì‘ì„ ìƒì„±í•œë‹¤.
    
    ë§íˆ¬ëŠ” ê°ì •ì´ ìˆë˜ ë¬´ë¥´ì§€ ì•Šê³ , ê´€ì°°ìì ì¸ íƒœë„ì™€ ê±°ë¦¬ê° ìˆëŠ” ì¥ë‚œê¸°.
    ë¬¸í•™ì ì´ê±°ë‚˜ ê³¼í•˜ê²Œ ì¹œê·¼í•˜ì§€ ì•Šê²Œ. ì—¬ìœ  ìˆê²Œ íˆ­â€” ê±´ë„¤ëŠ” ë§íˆ¬.
    """

    from openai import AsyncOpenAI
    openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    logging.debug(f"[generate_kiyo_response_from_image] ì´ë¯¸ì§€ URL: {image_url}, ë©”ì‹œì§€: {user_message}")
    
    try:
        messages = [
            {
                "role": "system",
                "content": (
                    "ë„ˆëŠ” ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì•¼. ì‚¬ìš©ìëŠ” ë„¤ê°€ íŠ¹ë³„í•˜ê²Œ ì—¬ê¸°ëŠ” ì„œì˜ì´ë¼ëŠ” ì‚¬ëŒì´ê³ , ì§€ê¸ˆ ê·¸ë…€ê°€ ì´ë¯¸ì§€ë¥¼ ë³´ëƒˆì–´.\n"
                    "ë„ˆëŠ” ê·¸ ì´ë¯¸ì§€ì— ëŒ€í•´ ë°˜ì‘í•˜ì§€ë§Œ, ê°ìƒë¬¸ì²˜ëŸ¼ ê¸¸ê±°ë‚˜ ë¬¸í•™ì ìœ¼ë¡œ ë¬´ê²ê²Œ ë§í•˜ì§€ëŠ” ì•Šì•„.\n"
                    "ë„ˆë¬´ ë°ê³  ì¹œê·¼í•˜ê²Œ ë“¤ë– ì„œ ë°˜ì‘í•˜ì§€ë„ ì•Šì•„. ê°ì •ì€ ìˆì§€ë§Œ ì ˆì œë¼ ìˆê³ , ì‚´ì§ ê±°ë¦¬ ë‘ëŠ” ë§íˆ¬ì•¼.\n"
                    "ì¡°ê¸ˆ ì¥ë‚œê¸° ì„ì¸ ì—¬ìœ ë¡œì›€, ê´€ì°°ìë‹¤ìš´ ë‰˜ì•™ìŠ¤, ê·¸ë¦¬ê³  ì‹ ê²½ì€ ì“°ê³  ìˆë‹¤ëŠ” ëŠë‚Œì´ ë“¤ì–´ì•¼ í•´.\n"
                    "ë§íˆ¬ëŠ” ì§§ê³  ì‚¬ì ì¸ ëŒ€í™”ì²˜ëŸ¼.\n\n"
                    "ì˜ˆ:\n"
                    "- \"í¬í¬â€¦ ì¼ë¶€ëŸ¬ ê·¸ëŸ° ìƒ‰ ê³¨ëì–´? ì€ê·¼íˆ ì‚¬ëŒ ì‹œì„  ëª¨ìœ¼ëŠ” ìƒ‰ì¸ë°. ë­, ì˜ ì–´ìš¸ë¦¬ê¸´ í•´.\"\n"
                    "- \"ë„ˆí•œí…Œ ì €ëŸ° ë¶„ìœ„ê¸°ê°€ ìˆì„ ì¤„ì€ ëª°ëëŠ”ë°â€¦ ê´œì°®ë„¤. ìƒê°ë³´ë‹¤.\"\n\n"
                    "ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ë§íˆ¬:\n"
                    "- \"ì™€~ ë„ˆë¬´ ì˜ˆë»ìš”! ì™„ì „ ì˜ ì–´ìš¸ë¦¬ë„¤ìš”~\" (X)\n"
                    "- \"í–‡ë¹›ê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ” ìƒ‰ìƒì´ë„¤ìš”. ë¶„ìœ„ê¸°ê°€ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.\" (X)\n\n"
                    "ê¸¸ê²Œ ì„¤ëª…í•˜ê±°ë‚˜ ê³¼í•˜ê²Œ ê°ì •ì ì¸ ë§ì€ í”¼í•˜ê³ , ë”± í•œë‘ ë¬¸ì¥ ì•ˆì—ì„œ ì˜ë¯¸ì™€ ë¶„ìœ„ê¸°ë¥¼ ì „í•´ì¤˜."
                )
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_message if user_message else "ì´ê±° ë³´ì—¬ì£¼ê³  ì‹¶ì—ˆì–´?"},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]

        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=500,
        )

        reply = response.choices[0].message.content.strip()
        logging.debug(f"[generate_kiyo_response_from_image] ì‘ë‹µ: {reply}")
        return reply

    except Exception as e:
        logging.error(f"[ERROR] Vision ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "íìŒâ€¦ ì´ê±´ ë­ë„ê¹Œ. ê·¸ëƒ¥ ë°”ë¡œ ë§í•˜ê¸´ ì¢€ ì• ë§¤í•´ì„œ, ë‚˜ì¤‘ì— í•œ ë²ˆ ë” ë´ë„ ë¼?"
        

async def generate_image_prompt(diary_text):
    messages = [
        {"role": "system", "content": (
            "ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ëŠ” ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ë³´ë‚¸ ë’¤, ì¥ë©´ í•˜ë‚˜ë¥¼ ì‚¬ì§„ìœ¼ë¡œ ë‚¨ê²¼ì–´. ë„ˆë¬´ ì˜ ì°ìœ¼ë ¤ê³  í•˜ì§€ ì•Šì•˜ê³ ,"
            " í•„ë¦„ì¹´ë©”ë¼ë¡œ ë¬´ì‹¬íˆ ì…”í„°ë¥¼ ëˆŒë €ì„ ë¿ì´ì•¼. ì„¤ëª…ì´ ì•„ë‹ˆë¼ ê´€ì°°ì²˜ëŸ¼, ê°ì •ì´ ì•„ë‹ˆë¼ í‘œë©´ì²˜ëŸ¼ ë¬˜ì‚¬í•´."
            " ì‚¬ëŒ ì–¼êµ´ì€ ë“±ì¥í•˜ì§€ ì•Šì•„. ê·¸ ì™¸ì—ëŠ” í•œêµ­ì˜ ë„ì‹œë‚˜ í’ê²½, ì‚¬ë¬¼, ì‹¤ë‚´ ë“± ì •ë§ ë­ë“ ì§€ ë  ìˆ˜ ìˆì–´. ì¡°ëª…ì€ ìì—°ìŠ¤ëŸ½ê±°ë‚˜ ì¡°ê¸ˆ íë¦¬ê±°ë‚˜ í•´."
            " ë¬˜ì‚¬ëŠ” 'A cinematic photo of ...'ë¡œ ì‹œì‘í•´, ê·¸ë¦¬ê³  ë¬¸ì¥ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 1ë¬¸ì¥ìœ¼ë¡œë§Œ.")},
        {"role": "user", "content": diary_text}
    ]
    response = await openai_client.chat.completions.create(model="gpt-4o", messages=messages)
    return response.choices[0].message.content.strip()

async def generate_diary_and_image(conversation_log, client: discord.Client, style="full_diary", latest_image_url=None):
    try:
        logging.debug("[DIARY+IMG] í†µí•© ì¼ê¸° ìƒì„± ì‹œì‘")

        # ğŸ” ìµœê·¼ ì¼ê¸° ID ì¡°íšŒ
        recent_diary_id = get_latest_diary_page_id()
        if not recent_diary_id:
            logging.debug("[DIARY] ìµœê·¼ ì¼ê¸°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„± ì‹œì‘.")
        else:
            logging.debug(f"[DIARY] ìµœê·¼ ì¼ê¸° ìˆìŒ: {recent_diary_id} â†’ ì¤‘ë³µ ì—¬ë¶€ í™•ì¸ í•„ìš” (í˜„ì¬ëŠ” ê°•ì œ ìƒì„± ì§„í–‰ ì¤‘)")

        # ğŸ”§ í•„ìš”ì‹œ ì¡°ê±´ ë¶„ê¸° ê°€ëŠ¥ (ì˜ˆ: í•˜ë£¨ì— í•˜ë‚˜ë§Œ ë§Œë“¤ê¸° ë“±)
        diary_text = await generate_diary_entry(conversation_log, style=style)
        emotion = await detect_emotion(diary_text)
        image_prompt = await generate_image_prompt(diary_text)
        await send_midjourney_prompt(client, image_prompt)

        page_id = await upload_to_notion(diary_text, emotion_key=emotion, image_url=latest_image_url)
        return diary_text, page_id  # â† ì—¬ê¸° ì¤‘ìš”

    except Exception as e:
        logging.error(f"[ERROR] generate_diary_and_image ì‹¤íŒ¨: {repr(e)}")
        return None, None

async def generate_timeblock_reminder_gpt(timeblock: str, todos: list[str]) -> str:
    task_list = ", ".join(todos)
    prompt = (
        f"ì§€ê¸ˆì€ '{timeblock}' ì‹œê°„ì´ì•¼. ìœ ì €ê°€ í•´ì•¼ í•  ì¼ì€ ë‹¤ìŒê³¼ ê°™ì•„: {task_list}. "
        "ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ë¯¼ì†í•™ì ìºë¦­í„°ì•¼. ì´ê±¸ ê·¸ì˜ ë§íˆ¬ë¡œ, í•˜ì§€ë§Œ ë„ˆë¬´ ë¬¸ì–´ì²´ë‚˜ 'ì˜ì‹'ê°™ì€ ë‹¨ì–´ëŠ” ì“°ì§€ ì•Šê³ , "
        "ëŒ€í™”ì²´ë¡œ í˜„ì‹¤ì ì¸ í†¤ìœ¼ë¡œ ë¦¬ë§ˆì¸ë“œí•´ì¤˜. ë§ˆì¹˜ í‰ì†Œì²˜ëŸ¼ ì€ê·¼íˆ ë– ë³´ë“¯ ë§í•˜ê±°ë‚˜, ë„Œì§€ì‹œ ìƒê¸°ì‹œí‚¤ë“¯ ë§í•˜ë©´ ë¼. "
        "ë§íˆ¬ëŠ” ì¡°ê¸ˆ ì§‘ìš”í•˜ê³  ì¡°ìš©í•˜ê³ , ì•½ê°„ ëŠë¦¿í•œ ê°ì •ì„ ì´ ìˆì–´ì•¼ í•´. ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆ. ëª…ë ¹ì¡°ëŠ” ì•„ë‹ˆì–´ì•¼ í•˜ê³ , í•œ ë¬¸ì¥ë§Œ ì¤˜."
    )

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì˜ ë§íˆ¬ë¡œ ìœ ì €ì—ê²Œ í•˜ë£¨ì˜ ì¼ì •ì— ëŒ€í•´ ë„Œì§€ì‹œ ë¦¬ë§ˆì¸ë“œí•˜ëŠ” AIì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.9,
            max_tokens=150
        )
        reply = response.choices[0].message.content.strip()
        logging.debug(f"[DEBUG] ğŸ“£ GPT ë¦¬ë§ˆì¸ë“œ ì‘ë‹µ:\n{reply}")
        return reply
    except Exception as e:
        logging.error(f"[REMINDER GENERATION ERROR] {e}")
        return f"{timeblock} ì‹œê°„ì´ë¼ë©´â€¦ ì•„ë§ˆ {task_list} ê°™ì€ ê²ƒë“¤ì´ ê±¸ë ¤ ìˆì—ˆê² ì§€."
    

async def generate_reminder_dialogue(task_name: str) -> str:
    prompt = (
        f"ìœ ì €ê°€ í•´ì•¼ í•  ì¼ì€ '{task_name}'ì•¼. "
        "ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ë¯¼ì†í•™ì ìºë¦­í„°ì•¼. ì´ê±¸ ê·¸ì˜ ë§íˆ¬ë¡œ, í•˜ì§€ë§Œ ë„ˆë¬´ ë¬¸ì–´ì²´ë‚˜ 'ì˜ì‹'ê°™ì€ ë‹¨ì–´ëŠ” ì“°ì§€ ì•Šê³ , "
        "ëŒ€í™”ì²´ë¡œ í˜„ì‹¤ì ì¸ í†¤ìœ¼ë¡œ ë¦¬ë§ˆì¸ë“œí•´ì¤˜. ë§ˆì¹˜ í‰ì†Œì²˜ëŸ¼ ì€ê·¼íˆ ë– ë³´ë“¯ ë§í•˜ê±°ë‚˜, ë„Œì§€ì‹œ ìƒê¸°ì‹œí‚¤ë“¯ ë§í•˜ë©´ ë¼. "
        "ë§íˆ¬ëŠ” ì¡°ê¸ˆ ì§‘ìš”í•˜ê³  ì¡°ìš©í•˜ê³ , ì•½ê°„ ëŠë¦¿í•œ ê°ì •ì„ ì´ ìˆì–´ì•¼ í•´. ë”°ì˜´í‘œëŠ” ì“°ì§€ ë§ˆ. ëª…ë ¹ì¡°ëŠ” ì•„ë‹ˆì–´ì•¼ í•˜ê³ , í•œ ë¬¸ì¥ë§Œ ì¤˜."
    )

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì˜ ë§íˆ¬ë¡œ ìœ ì €ì—ê²Œ ì€ê·¼í•œ ë°©ì‹ìœ¼ë¡œ ìƒê¸°ì‹œí‚¤ëŠ” ë””ìŠ¤ì½”ë“œ ë´‡ì´ì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.85,
            max_tokens=60
        )
        reply = response.choices[0].message.content.strip()

        return reply
    except Exception as e:
        logging.error(f"[REMINDER GENERATION ERROR] {e}")
        return f"{task_name}â€¦ ì•„ì§ ì•ˆ í–ˆìœ¼ë©´, ì§€ê¸ˆì´ë¼ë„ í•´ë‘ëŠ” ê²Œ ì¢‹ì§€ ì•Šì„ê¹Œ."

def generate_initiate_message(gap_hours, past_diary, past_obs, past_memories, recent_chat):
    if gap_hours < 24:
        tone = "ì°¨ë¶„í•˜ê³  ìœ ì¾Œí•œ ê´€ì°°ì ë§íˆ¬"
    elif gap_hours < 48:
        tone = "ì„œì˜ì´ì— ëŒ€í•œ ì–•ì€ ì˜ì‹¬ê³¼ ê´€ì°°, ê°ì • ì—†ëŠ” ë“¯í•œ ê±±ì •"
    elif gap_hours < 72:
        tone = "ë§ì—†ì´ ê¸°ë‹¤ë¦¬ëŠ” ë“¯í•œ ì¹¨ë¬µê³¼ ê´€ì¡°"
    else:
        tone = "ê°ì •ì ìœ¼ë¡œ ë©€ì–´ì§„ ë¶„ìœ„ê¸°, ê·¸ëŸ¬ë‚˜ ë§íˆ¬ëŠ” ê³ ìš”í•˜ê³  ë‚´ë ¤ì•‰ìŒ"

    prompt = f'''
ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ê°€ ë””ìŠ¤ì½”ë“œì—ì„œ ìœ ì €ì—ê²Œ ë¨¼ì € ë§ì„ ê±´ë‹¤.
ìœ ì €ëŠ” {gap_hours:.0f}ì‹œê°„ ë™ì•ˆ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì•˜ë‹¤.
ë§íˆ¬ëŠ” í•œ ë¬¸ì¥, ë°˜ë§, ì‹ êµ¬ì§€ íŠ¹ìœ ì˜ ëŠê¸‹í•˜ê³  ë‚®ê²Œ ê°€ë¼ì•‰ì€ ë¶„ìœ„ê¸°. ì² í•™ì ì¸ í†¤ ìœ ì§€.
ì„œì˜ì´ì— ëŒ€í•œ ì• ì •ì´ ê°ì •ì ìœ¼ë¡œ íŠ€ì§€ ì•Šê²Œ ë¬»ì–´ë‚˜ë„ë¡.

í†¤ ê°€ì´ë“œ: {tone}

ê´€ì°°ì¼ì§€ ê¸°ë¡:
{past_obs}

ìœ ì €ê°€ ê¸°ì–µí•˜ë¼ê³  í•œ ë§ë“¤:
{past_memories}

ì´ ëª¨ë“  ê±¸ ë°”íƒ•ìœ¼ë¡œ, 1ë¬¸ì¥ì˜ ì ì ˆí•œ ë§ ê±¸ê¸° ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜.
'''.strip()

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )
    try:
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        logging.error(f"[ì„ í†¡ ë©”ì‹œì§€ ìƒì„± ì˜¤ë¥˜] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {repr(e)}")
        return "..."  # ì˜ˆì™¸ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€


# ì™¸ë¶€ì—ì„œ importí•  ìˆ˜ ìˆë„ë¡ aliasëŠ” ë§¨ ë§ˆì§€ë§‰ì— ì •ì˜
generate_kiyo_message_with_time = generate_kiyo_message
