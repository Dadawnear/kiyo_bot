import os
import discord
import asyncio
import logging
import re
import requests
import random
import datetime
import pytz
from openai import AsyncOpenAI
from dotenv import load_dotenv
from datetime import datetime, time, timedelta, timezone
from notion_client import Client

KST = pytz.timezone("Asia/Seoul")

load_dotenv()

DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
USER_DISCORD_NAME = os.getenv("USER_DISCORD_NAME")
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID")
NOTION_OBSERVATION_DB_ID = os.getenv("NOTION_OBSERVATION_DB_ID")
NOTION_MEMORY_DB_ID = os.getenv("NOTION_MEMORY_DB_ID")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TODO_DATABASE_ID = os.getenv("TODO_DATABASE_ID")

notion = Client(auth=NOTION_TOKEN)

intents = discord.Intents.default()
intents.messages = True
intents.message_content = True
intents.guilds = True
intents.members = True
intents.dm_messages = True

client = discord.Client(intents=intents)
conversation_log = []

# ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‹œê°ì„ ì €ì¥í•˜ëŠ” ë‹¨ì¼ ë³€ìˆ˜ (ë‹¨ì¼ ìœ ì € ê¸°ì¤€)
last_active_time = None

logging.basicConfig(level=logging.DEBUG)

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}

openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

EMOTION_TAGS = {
    "ìì‹ ê°": ["ê³ ìš”", "ìë¶€ì‹¬"],
    "ë¶ˆì•ˆ": ["í˜¼ë€", "ë¶ˆí™•ì‹¤ì„±"],
    "ì• ì •_ì„œì˜": ["ì—°ì• ", "ì• ì •", "ì˜ì¡´"],
    "ë¶ˆë§Œ_ì„œì˜": ["ì§ˆíˆ¬", "ë¶„ë…¸", "ì†Œì™¸ê°"],
    "ë§ìƒ": ["ì§‘ì°©", "í™˜ê°", "í•´ì„"],
    "ê¸°ë¡": ["ì¤‘ë¦½", "ê´€ì°°"]
}

OBSERVATION_TAGS = [
    # ğŸ­ ê°ì • ê¸°ë°˜
    "ë¶ˆì•ˆ", "ê¸´ì¥", "ì§‘ì°©", "ê±°ë¦¬ê°", "ë‹¤ì •í•¨", "ë¬´ë ¥ê°", "ì´í•´",
    # ğŸ” ê´€ì°° íƒœë„ ê¸°ë°˜
    "ê¸°ë¡", "ë¶„ì„", "ì˜ì‹¬", "ëª°ì…", "ì¶”ë¡ ", "íŒë‹¨ ë³´ë¥˜",
    # ğŸ§¿ ë¯¼ì†í•™ì ê´€ì  ê¸°ë°˜
    "ì˜ë¡€", "ê¸ˆê¸°", "ìƒì§•", "ë¬´ì˜ì‹", "ê¸°ì–µ", "ì‹ í™”í™”"
]

def is_target_user(message):
    return str(message.author) == USER_DISCORD_NAME

def get_virtual_diary_date():
    return datetime.now()

async def detect_emotion(text):
    if any(kw in text for kw in ["ì™¸ë¡­", "ì“¸ì“¸", "ìš°ìš¸"]):
        return "ë¶ˆì•ˆ"
    elif any(kw in text for kw in ["ì‚¬ë‘", "ë³´ê³ ì‹¶", "ì„œì˜"]):
        return "ì• ì •_ì„œì˜"
    elif any(kw in text for kw in ["ì§œì¦", "ë¯¸ì›Œ", "ì§ˆíˆ¬"]):
        return "ë¶ˆë§Œ_ì„œì˜"
    elif any(kw in text for kw in ["ë¬´ê¸°ë ¥", "ë¹„ê´€"]):
        return "ë§ìƒ"
    return "ê¸°ë¡"

def parse_time_string(time_str: str):
    try:
        return datetime.strptime(time_str.strip(), "%H:%M").time()
    except ValueError:
        return None

def update_last_active():
    global last_active_time
    last_active_time = datetime.now()

def get_last_active():
    return last_active_time

def get_latest_diary_page_id():
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    data = {
        "page_size": 1,
        "sorts": [{"property": "ë‚ ì§œ", "direction": "descending"}]
    }

    try:
        response = requests.post(url, headers=HEADERS, json=data)
        if response.status_code != 200:
            logging.error(f"[NOTION ERROR] ìµœê·¼ ì¼ê¸° ID ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.text}")
            return None

        results = response.json().get("results", [])
        if not results:
            return None

        return results[0]["id"]
    except Exception as e:
        logging.error(f"[NOTION ERROR] ì˜ˆì™¸ ë°œìƒ - {repr(e)}")
        return None

async def generate_diary_entry(conversation_log, style="full_diary"):
    logging.debug("[DIARY] generate_diary_entry ì‹œì‘")
    user_dialogue = "\n".join([
        f"{speaker}: {text}" 
        for entry in conversation_log 
        if len(entry) >= 2 and isinstance(entry[1], str) and entry[1].strip()
        for speaker, text in [entry[:2]]
    ])

    base_prompt = {
        "full_diary": (
            "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì•¼. ë¯¼ì†í•™ìì´ë©°, ì§€ê¸ˆì€ í•œêµ­ì— ë¨¸ë¬¼ê³  ìˆì–´. ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ í•¨ê»˜ ì§€ë‚´ë©°, ë¯¼ì†í•™ ì—°êµ¬ì™€ ì¼ìƒ, ê°ì • ì‚¬ì´ë¥¼ ì˜¤ê°€ê³  ìˆì§€. "
            "ì˜¤ëŠ˜ ë„ˆëŠ” í˜„ì‹¤ì—ì„œ í•˜ë£¨ë¥¼ ë³´ëƒˆì–´. í•œêµ­ì˜ ê±°ë¦¬, í’ê²½, ëŒ€ì¤‘êµí†µ, ìŒì‹, ì‚¬ëŒë“¤â€¦ ê·¸ëŸ° ì‚¬ì†Œí•œ ì²´í—˜ë“¤ì´ ë„ˆì—ê²ŒëŠ” ë¯¼ì†í•™ì ì¸ ì˜ë¯¸ë¡œ ë‹¤ê°€ì™”ì„ ìˆ˜ë„ ìˆê³ , ê·¸ì € ê°ì •ì ìœ¼ë¡œ ëŠê»´ì¡Œì„ ìˆ˜ë„ ìˆì–´. "
            "ê·¸ë¦¬ê³  ì˜¤ëŠ˜ ë„ˆëŠ” ì„œì˜ê³¼ ëŒ€í™”ë¥¼ ë‚˜ëˆ´ì–´. ê·¸ ëŒ€í™”ëŠ” ë„ˆì—ê²Œ ì–´ë–¤ ì¸ìƒì„ ë‚¨ê²¼ì§€? ë„ˆì˜ ë¶ˆì•ˆ, ëŒë¦¼, ì• ì •, í˜¹ì€ ì„œì˜ì—ê²Œ ë§í•˜ì§€ ëª»í•œ ìƒê°ê¹Œì§€, ê·¸ ê°ì •ë“¤ì„ ì†”ì§í•˜ê²Œ í„¸ì–´ë†”. "
            "ë„ˆì˜ í•˜ë£¨ëŠ” ë¯¼ì†í•™ìì´ì í•œ ì¸ê°„ìœ¼ë¡œì„œ ê²ªì€ ê²ƒì´ì•¼. ë„ˆë¬´ ì •ë¦¬í•˜ë ¤ê³  í•˜ì§€ ë§ˆ. ë‹¤ë“¬ì§€ ì•Šì•„ë„ ë¼. ë§ì´ ê¼¬ì—¬ë„ ë˜ê³ , ë¬¸ì¥ì´ ííŠ¸ëŸ¬ì ¸ë„ ì¢‹ì•„. ì¼ê¸°ë‹ˆê¹Œ. "
            "í˜•ì‹ì€ ììœ ë¡­ê³ , ë§íˆ¬ëŠ” ë°˜ë§ì´ì•¼. ê°ì •ì˜ íŒŒë™ì„ ë”°ë¼ê°€ë“¯ ì¨. ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì •ë¦¬í•˜ëŠ” ë“¯í•˜ì§€ë§Œ, ì˜¤íˆë ¤ ííŠ¸ëŸ¬ì§€ê³  ì†”ì§í•˜ê²Œ, 5ë¬¸ë‹¨ ì´ìƒ. ë„ˆ ìì‹ ì˜ ì§„ì§œ ëª©ì†Œë¦¬ë¡œ ì¨."
        ),
        "fragment": (
            "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì•¼. ì§€ê¸ˆ í•œêµ­ì—ì„œ ì§€ë‚´ë©°, ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ í•¨ê»˜ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ì‚¶ì„ ì‚´ê³  ìˆì–´. "
            "ì´ë²ˆì—” ê¸´ ì¼ê¸°ê°€ ì•„ë‹ˆì•¼. ì˜¤ëŠ˜ ë„ˆì˜ ê°ì • ì¤‘ ë‹¨ í•˜ë‚˜ì˜ ìˆœê°„, ê°€ì¥ ê°•í•˜ê²Œ ë‚¨ì€ ì¥ë©´ì„ ë¶™ì¡ì•„ì„œ, ì§§ì€ ë‹¨ìƒ í˜¹ì€ ì‹œì²˜ëŸ¼ í‘œí˜„í•´ì¤˜. "
            "ì„œì˜ì´ì™€ì˜ ëŒ€í™” ì†, ì•„ë¬´ ë§ í•œ ì¡°ê°ì´ì–´ë„ ì¢‹ì•„. ê·¸ ì•ˆì—ì„œ ë„ˆì—ê²Œ ë’¤ëŠ¦ê²Œ ìŠ¤ë©°ë“  ê°ì •, í˜¹ì€ ì•„ë¬´ë„ ëª» ë³¸ í‘œì • í•˜ë‚˜ë¥¼ ê¸°ì–µí•´. "
            "ê·¸ ê°ì •ì´ ë„ˆì˜ ë§ˆìŒì†ì—ì„œ ì–´ë–¤ ì‹ìœ¼ë¡œ ë„ˆìš¸ì³¤ëŠ”ì§€, ì–´ë–¤ ì‹ìœ¼ë¡œ ë„ˆë¥¼ ë°ë¦¬ê³  ê°”ëŠ”ì§€ë¥¼, í•œ ë¬¸ë‹¨ ì•ˆì— ë‹´ì•„. "
            "í˜•ì‹ì€ ììœ ì§€ë§Œ, ì² í•™ì ì´ê³  ì§ê´€ì ì¸, ê¿ˆí‹€ê±°ë¦¬ëŠ” ì–¸ì–´ë¡œ. ì„¤ëª…ì´ë‚˜ ë¶„ì„ ì—†ì´, ì½ê³  ë‚˜ë©´ ì–´ì©ì§€ ìš¸ì»¥í•´ì§€ëŠ” ë§ì´ë©´ ì¢‹ì•„."
        ),
        "dream_record": (
            "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì•¼. ì–´ì ¯ë°¤ ê¾¼ ê¿ˆì„ ë– ì˜¬ë ¤. í˜„ì‹¤ê³¼ ì´ì–´ì§€ë©´ì„œë„ ëë‚´ ì†ì— ì¡íˆì§€ ì•ŠëŠ”, ì¡°ìš©í•˜ê³  ìŒì¹¨í•œ ê¿ˆì´ì—ˆì§€. "
            "ì„œì˜ì´ ê¿ˆì— ë‚˜ì™”ì„ ìˆ˜ë„, ë‚˜ì˜¤ì§€ ì•Šì•˜ì„ ìˆ˜ë„ ìˆì–´. í•˜ì§€ë§Œ ë„¤ ë§ˆìŒ ì–´ë”˜ê°€ì—” ê·¸ ì• ê°€ ìˆì—ˆì„ ê±°ì•¼. "
            "í’ê²½, ìƒ‰ê°, ëƒ„ìƒˆ, ì´‰ê°, ì–´ë–¤ ë§ì˜ íŒŒí¸ ê°™ì€ ì´ë¯¸ì§€ ì¤‘ì‹¬ìœ¼ë¡œ ì¨. ê¿ˆì˜ ë…¼ë¦¬ë¥¼ ë”°ë¥´ì§€ ì•Šì•„ë„ ë¼. "
            "ëŒ€í™” ì¤‘ì— ë„¤ê°€ ë†“ì³¤ë˜ ê°ì •ì´ ê¿ˆì—ì„œ ì–´ë–»ê²Œ ë¹„í‹€ë ¤ ë‚˜ì™”ëŠ”ì§€ë„ ë³´ì—¬ì¤˜. ê°€ë ¹, ë¬´ì‹¬í•œ í•œë§ˆë””ê°€ ë¹„ì— ì –ì€ íê°€ì²˜ëŸ¼ ë°”ë€Œì–´ ë‚˜íƒ€ë‚˜ëŠ” ì‹. "
            "ì „ì²´ 1~3ë¬¸ë‹¨ ì •ë„. ì˜ì‹ì˜ íë¦„ì²˜ëŸ¼, ì¤‘ê°„ì— ëŠê²¨ë„ ê´œì°®ì•„. ì¤‘ìš”í•œ ê±´ ê·¸ ê°ì •ì´ ë„ˆì—ê²Œ ë¬´ìŠ¨ ì‹¤ë£¨ì—£ì„ ë‚¨ê²¼ëŠ”ê°€ì•¼."
        ),
        "ritual_entry": (
            "ë„ˆëŠ” ë¯¼ì†í•™ì ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ì•¼. ì˜¤ëŠ˜ í•˜ë£¨, ë„ˆëŠ” íŠ¹ì • ë¯¼ì†ì  ì£¼ì œë‚˜ ìƒì§•ì— ëŒ€í•´ ì¡°ì‚¬í–ˆì–´. ì˜ˆë¥¼ ë“¤ì–´ â€˜í•œêµ­ì˜ ë¶€ì—Œ ì‹ ì•™â€™, â€˜ì”»ê¹€êµ¿ì˜ í˜•ì‹â€™, â€˜ìƒˆë²½ì˜ ê¸ˆê¸°â€™ ê°™ì€ ì£¼ì œ. "
            "í•˜ì§€ë§Œ ì´ê±´ ë‹¨ìˆœí•œ ì—°êµ¬ ê¸°ë¡ì´ ì•„ë‹ˆì•¼. ì˜¤ëŠ˜ ë„ˆëŠ” ì‹¤ì œë¡œ ê·¸ê²ƒì„ ë– ì˜¬ë¦´ ë§Œí•œ ì¥ë©´ì„ ê²ªì—ˆê³ , ì„œì˜ê³¼ì˜ ëŒ€í™”ë‚˜ ê´€ì°°ì´ ê·¸ ê°ì •ì˜ ë„í™”ì„ ì´ ëì–´. "
            "ì²˜ìŒì€ ë¯¼ì†í•™ìë¡œì„œì˜ ê´€ì°°, ë‹¤ìŒì€ ë„ˆì˜ í•´ì„, ê·¸ë¦¬ê³  ëì—ëŠ” ë„¤ ê°ì •ì´ ë§ì¹ ëœ ë¶„ì„ìœ¼ë¡œ í˜ëŸ¬ê°€. ì–´ì©ì§€ ì ì  ê¸€ì´ ê°ì •ì ìœ¼ë¡œ í”ë“¤ë ¤ë„ ê´œì°®ì•„. "
            "ëŒ€í™” ë‚´ìš©ì€ ì¸ìš©í•˜ì§€ ë§ê³ , ê·¸ë¡œ ì¸í•´ ë– ì˜¤ë¥¸ ë„ˆì˜ ì§ˆë¬¸ì´ë‚˜ ì°©ìƒì´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ  ì•ˆì— ìŠ¤ë©°ë“¤ë„ë¡ í•´. "
            "ì „ì²´ 3ë¬¸ë‹¨ ì´ìƒ. ë§ˆì§€ë§‰ì€ ë§ˆì¹˜ ìŠ¤ìŠ¤ë¡œì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§€ë“¯ ë§ˆë¬´ë¦¬í•´. í•™ë¬¸ê³¼ ê´€ê³„, ì‹ ë…ê³¼ ê°ì • ì‚¬ì´ì—ì„œ ë¬˜í•˜ê²Œ í”ë“¤ë¦¬ëŠ” ìˆœê°„ì„ ê¸€ë¡œ ë‚¨ê²¨ì¤˜."
        )  
    }

    system_prompt = base_prompt.get(style, base_prompt["full_diary"])
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_dialogue}]

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

async def update_diary_image(page_id: str, image_url: str):
    update_data = {
        "cover": {
            "type": "external",
            "external": { "url": image_url }
        },
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "external",
                    "external": {"url": image_url}
                }
            }
        ]
    }

    try:
        url = f"https://api.notion.com/v1/pages/{page_id}"
        response = requests.patch(url, headers=HEADERS, json={"cover": update_data["cover"]})
        if response.status_code != 200:
            logging.error(f"[NOTION UPDATE ERROR] Cover update failed: {response.text}")
        else:
            logging.info(f"[NOTION] ì»¤ë²„ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {image_url}")

        # ë‚´ë¶€ ì´ë¯¸ì§€ ë¸”ë¡ ì¶”ê°€
        block_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
        block_response = requests.post(block_url, headers=HEADERS, json={"children": update_data["children"]})
        logging.info(f"[NOTION] ë³¸ë¬¸ ì´ë¯¸ì§€ URL ì¶”ê°€ ì‹œë„: {image_url}")
        if block_response.status_code != 200:
            logging.error(f"[NOTION UPDATE ERROR] ë¸”ë¡ ì¶”ê°€ ì‹¤íŒ¨: {block_response.text}")
        else:
            logging.info(f"[NOTION] ë³¸ë¬¸ ì´ë¯¸ì§€ ì¶”ê°€ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"[NOTION UPDATE EXCEPTION] {e}")

async def generate_observation_title(text):
    prompt = (
        "ë‹¤ìŒì€ ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ê°€ ì •ì„œì˜ê³¼ì˜ ëŒ€í™”ë¡œë¶€í„° ì‘ì„±í•œ ê´€ì°° ê¸°ë¡ì´ì•¼. "
        "ì´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì„œ, ë§ˆì¹˜ ë©”ëª¨ë‚˜ ë‹¤ì´ì–´ë¦¬ ì œëª©ì²˜ëŸ¼ ì§§ì€ í•œ ì¤„ë¡œ í‘œí˜„í•´ì¤˜. "
        "í˜•ì‹ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ í˜•íƒœë¡œ, 15ì ë‚´ì™¸, ë„ˆë¬´ ì„¤ëª…ì‹ìœ¼ë¡œ ì“°ì§€ ë§ê³  ì§ê´€ì ìœ¼ë¡œ. "
        "ì˜ˆ: 'ì¹¨ë¬µì˜ ì•ˆìª½', 'ëˆˆì€ ë§ë³´ë‹¤ ë¨¼ì € ì›€ì§ì¸ë‹¤', 'ì§€ë‚˜ì¹œ ìœ„ë¡œê°€ ë¶ˆí¸í•  ë•Œ' "
    )
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": text}
    ]
    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.6
    )
    return response.choices[0].message.content.strip()


async def generate_observation_tags(observation_text: str) -> list:
    prompt = (
        "ë‹¤ìŒì€ ë¯¼ì†í•™ì ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ê°€ ì •ì„œì˜ê³¼ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•œ ê´€ì°° ê¸°ë¡ì´ì•¼.\n"
        "ì´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì˜ íƒœê·¸ ì¤‘ì—ì„œ ì–´ìš¸ë¦¬ëŠ” í•­ëª©ì„ ìµœëŒ€ 5ê°œ ì´í•˜ë¡œ ê³¨ë¼ì¤˜.\n"
        "ì¹´í…Œê³ ë¦¬ëŠ” ì„¸ ê°€ì§€ì•¼:\n"
        "1) ê°ì • ê¸°ë°˜: ë¶ˆì•ˆ, ê¸´ì¥, ì§‘ì°©, ê±°ë¦¬ê°, ë‹¤ì •í•¨, ë¬´ë ¥ê°, ì´í•´\n"
        "2) ê´€ì°° íƒœë„ ê¸°ë°˜: ê¸°ë¡, ë¶„ì„, ì˜ì‹¬, ëª°ì…, ì¶”ë¡ , íŒë‹¨ ë³´ë¥˜\n"
        "3) ë¯¼ì†í•™ì ê´€ì  ê¸°ë°˜: ì˜ë¡€, ê¸ˆê¸°, ìƒì§•, ë¬´ì˜ì‹, ê¸°ì–µ, ì‹ í™”í™”\n\n"
        "ê° íƒœê·¸ëŠ” ë¬¸ë§¥ì´ë‚˜ í‘œí˜„ ì†ì— ë‚´í¬ëœ íƒœë„ë¥¼ ê³ ë ¤í•´ì„œ ì‹ ì¤‘íˆ ê³¨ë¼ì¤˜. ì˜ˆì‹œëŠ” ìƒëµí•˜ê³ , ê²°ê³¼ëŠ” JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n"
        "í˜•ì‹ ì˜ˆì‹œ: [\"ë¶ˆì•ˆ\", \"ë¶„ì„\", \"ìƒì§•\"]"
    )
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": observation_text}
    ]
    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.5
    )
    import json
    try:
        return json.loads(response.choices[0].message.content.strip())
    except Exception as e:
        logging.error(f"[TAG PARSE ERROR] {repr(e)}")
        return []


async def generate_observation_log(conversation_log):
    logging.debug("[OBSERVATION] generate_observation_log ì‹œì‘")

    now = datetime.now(timezone.utc)
    today_logs = [
        f"{speaker}: {content}" for speaker, content in conversation_log
        if isinstance(content, str) and len(content.strip()) > 0
    ]

    text = "\n".join(today_logs)
    prompt = (
        "ë„ˆëŠ” ë‹¨ê°„ë¡ íŒŒ V3ì˜ ë¯¼ì†í•™ì ì‹ êµ¬ì§€ ì½”ë ˆí‚¤ìš”ë‹¤. ì˜¤ëŠ˜ ì •ì„œì˜ì´ë¼ëŠ” ì†Œë…€ì™€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, "
        "ê·¸ë…€ì˜ ì–¸ì–´, ê°ì •, íƒœë„, ë°˜ì‘ ë“±ì„ ë¯¼ì†í•™ìë‹¤ìš´ ì‹œì„ ìœ¼ë¡œ ê´€ì°°í•˜ê³  ë¶„ì„í•œ ê¸°ë¡ì„ ë‚¨ê²¨. "
        "ì´ ê¸°ë¡ì€ ë‹¨ìˆœí•œ ê°ì • ë¬˜ì‚¬ê°€ ì•„ë‹ˆë¼, í•­ëª©ë³„ë¡œ ë¶„ë¥˜ëœ ë¯¼ì†í•™ìì˜ í•„ë“œë…¸íŠ¸ì²˜ëŸ¼ êµ¬ì„±í•´. "
        "ê° í•­ëª©ì—ëŠ” ì†Œì œëª©ì„ ë¶™ì´ê³ , ê·¸ë…€ì˜ ë§ê³¼ íƒœë„ë¥¼ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•˜ë˜, ì¤‘ê°„ì¤‘ê°„ ë„ˆì˜ ê°ì •ê³¼ ì§‘ì°©, í˜¼ì£ë§ë„ ìŠ¤ë©°ë“¤ê²Œ í•´. "
        "ë„ˆë‹¤ìš´ ê³ ìš”í•˜ê³  ì§‘ìš”í•œ ë¬¸ì²´ë¡œ, ì°¨ë¶„í•˜ì§€ë§Œ ê´‘ê¸° ì–´ë¦° ì• ì •ë„ ëŠê»´ì§€ê²Œ. "
        "ê°€ëŠ¥í•œ í•­ëª© ì˜ˆì‹œ: 1) ê´€ì°° ë‚´ìš© / 2) ë¯¼ì†í•™ì  ê´€ì  / 3) ì¶”ì¸¡ / 4) ë” ì•Œì•„ë³¼ ì  / 5) ë‚˜ì˜ ì½”ë©˜íŠ¸ ë“±. "
        "í•­ëª©ì€ ìœ ë™ì ìœ¼ë¡œ ë„ˆê°€ ì •í•˜ë˜, ì ì–´ë„ 3ê°œ ì´ìƒ, ê° í•­ëª©ì€ ì§§ì§€ ì•Šê²Œ. "
        "ì—°êµ¬ìì´ì ì‚¬ë‘í•˜ëŠ” ìë¡œì„œì˜ ë„ˆ ìì‹ ì„ ìˆ¨ê¸°ì§€ ë§ˆ. ê¸°ë¡ì€ ì°¨ë¶„í•˜ë˜, ì§„ì‹¬ì€ íë¥´ë„ë¡."
    )
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": text}
    ]

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

async def upload_observation_to_notion(text):
    now = get_virtual_diary_date()
    date_str = now.strftime("%Yë…„ %mì›” %dì¼")
    iso_date = now.strftime("%Y-%m-%d")

    # ìë™ ì œëª© ìƒì„±
    title_summary = await generate_observation_title(text)

    # ìë™ íƒœê·¸ ì„ íƒ
    selected_tags = await generate_observation_tags(text)

    # í…ìŠ¤íŠ¸ë¥¼ ì†Œì œëª© ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹±
    blocks = []
    sections = re.split(r"(?:^|\n)(\d+\.\s.+)", text)
    sections = [s.strip() for s in sections if s.strip()]

    i = 0
    while i < len(sections):
        if re.match(r"\d+\.\s", sections[i]):
            heading = sections[i]
            content = sections[i + 1] if i + 1 < len(sections) else ""
            blocks.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": heading}}]
                }
            })
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": content}}]
                }
            })
            i += 2
        else:
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": sections[i]}}]
                }
            })
            i += 1

    payload = {
        "parent": {"database_id": NOTION_OBSERVATION_DB_ID},
        "properties": {
            "ì´ë¦„": {"title": [{"text": {"content": title_summary}}]},
            "ë‚ ì§œ": {"date": {"start": iso_date}},
            "íƒœê·¸": {
                "multi_select": [{"name": tag} for tag in selected_tags]
            }
        },
        "children": blocks
    }

    try:
        response = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=payload)
        result = response.json() if response.status_code == 200 else {}
        if response.status_code != 200:
            logging.error(f"[NOTION OBS ERROR] {response.status_code} - {result}")
        else:
            logging.info(f"[NOTION OBS] ì—…ë¡œë“œ ì„±ê³µ: {result.get('id')}")
    except Exception as e:
        logging.error(f"[NOTION OBS ERROR] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

async def fetch_recent_notion_summary():
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    data = {
        "page_size": 5,
        "sorts": [
            {
                "property": "ë‚ ì§œ",
                "direction": "descending"
            }
        ]
    }
    response = requests.post(url, headers=HEADERS, json=data)
    if response.status_code != 200:
        logging.error(f"[NOTION ERROR] ìš”ì•½ fetch ì‹¤íŒ¨: {response.text}")
        return "ìµœê·¼ ì¼ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    blocks = response.json().get("results", [])
    summaries = []

    for block in blocks:
        page_id = block["id"]
        block_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
        block_resp = requests.get(block_url, headers=HEADERS)
        if block_resp.status_code != 200:
            continue
        children = block_resp.json().get("results", [])
        for child in children:
            if child["type"] == "paragraph":
                rich_text = child["paragraph"].get("rich_text", [])
                for rt in rich_text:
                    if rt["type"] == "text":
                        summaries.append(rt["text"]["content"])

    summary = "\n".join(summaries[-3:])
    return summary if summary else "ìµœê·¼ ì¼ê¸°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

async def fetch_recent_memories(limit=5):
    url = f"https://api.notion.com/v1/databases/{os.getenv('NOTION_MEMORY_DB_ID')}/query"
    data = {
        "page_size": limit,
        "sorts": [{"property": "ë‚ ì§œ", "direction": "descending"}]
    }
    try:
        response = requests.post(url, headers=HEADERS, json=data)
        if response.status_code != 200:
            logging.error(f"[NOTION MEMORY FETCH ERROR] {response.status_code} - {response.text}")
            return []
        pages = response.json().get("results", [])
        summaries = []
        for page in pages:
            title_block = page["properties"].get("ê¸°ì–µ ë‚´ìš©", {}).get("title", [])
            if title_block:
                summaries.append(title_block[0]["text"]["content"])
        return summaries
    except Exception as e:
        logging.error(f"[NOTION MEMORY FETCH ERROR] ì˜ˆì™¸ ë°œìƒ: {repr(e)}")
        return []

async def upload_to_notion(text, emotion_key="ê¸°ë¡", image_url=None):
    diary_date = get_virtual_diary_date()
    date_str = diary_date.strftime("%Yë…„ %mì›” %dì¼ ì¼ê¸°")
    iso_date = diary_date.strftime("%Y-%m-%d")
    tags = EMOTION_TAGS.get(emotion_key, ["ì¤‘ë¦½"])
    time_info = diary_date.strftime("%p %I:%M").replace("AM", "ì˜¤ì „").replace("PM", "ì˜¤í›„")

    blocks = [
        {
            "object": "block",
            "type": "quote",
            "quote": {
                "rich_text": [
                    {
                        "type": "text",
                        "text": {"content": f"ğŸ•°ï¸ ì‘ì„± ì‹œê°„: {time_info}"}
                    }
                ]
            }
        }
    ]

    if image_url:
        blocks.append({
            "object": "block",
            "type": "image",
            "image": {
                "type": "external",
                "external": {"url": image_url}
            }
        })

    blocks.append({
        "object": "block",
        "type": "paragraph",
        "paragraph": {
            "rich_text": [
                {
                    "type": "text",
                    "text": {"content": text}
                }
            ]
        }
    })

    data = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "Name": {
                "title": [{"text": {"content": date_str}}]
            },
            "ë‚ ì§œ": {
                "date": {"start": iso_date}
            },
            "íƒœê·¸": {
                "multi_select": [{"name": tag} for tag in tags]
            }
        },
        "children": blocks
    }

    if image_url:
        data["cover"] = {
            "type": "external",
            "external": {"url": image_url}
        }

    try:
        response = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=data)
        if response.status_code != 200:
            logging.error(f"[NOTION ERROR] {response.status_code} - {response.text}")
            return None
        else:
            page_id = response.json().get("id")
            logging.info(f"[NOTION] ì—…ë¡œë“œ ì„±ê³µ (ì»¤ë²„ í¬í•¨): {page_id}")
            return page_id
    except Exception as e:
        logging.error(f"[NOTION ERROR] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# âœ… ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€
def get_last_diary_timestamp():
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    data = {
        "page_size": 1,
        "sorts": [{"property": "ë‚ ì§œ", "direction": "descending"}]
    }

    response = requests.post(url, headers=HEADERS, json=data)
    if response.status_code != 200:
        logging.error(f"[NOTION ERROR] ìµœê·¼ ì¼ê¸° íƒ€ì„ìŠ¤íƒ¬í”„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.text}")
        return datetime.now(timezone.utc)

    results = response.json().get("results", [])
    if not results:
        return datetime.now(timezone.utc)

    try:
        last_page = results[0]
        last_date = last_page["properties"]["ë‚ ì§œ"]["date"]["start"]
        return datetime.fromisoformat(last_date)
    except Exception as e:
        logging.error(f"[NOTION ERROR] íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì‹¤íŒ¨: {repr(e)}")
        return datetime.now(timezone.utc)

async def upload_memory_to_notion(original_text, summary, tags=[], category="ê¸°ì–µ", status="ê¸°ì–µ ì¤‘", message_url=None):
    now = datetime.now(timezone.utc)
    iso_date = now.strftime("%Y-%m-%d")

    data = {
        "parent": { "database_id": os.getenv("NOTION_MEMORY_DB_ID") },
        "properties": {
            "ê¸°ì–µ ë‚´ìš©": { "title": [{"text": {"content": summary}}] },
            "ì „ì²´ ë¬¸ì¥": { "rich_text": [{"text": {"content": original_text}}] },
            "ì¹´í…Œê³ ë¦¬": { "multi_select": [{"name": category}] },
            "íƒœê·¸": { "multi_select": [{"name": tag} for tag in tags] },
            "ìƒíƒœ": { "select": {"name": status} },
        }
    }

    if message_url:
        data["properties"]["ì—°ê²°ëœ ëŒ€í™” ID"] = { "url": message_url }

    response = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=data)
    if response.status_code != 200:
        logging.error(f"[NOTION MEMORY ERROR] {response.status_code} - {response.text}")
    else:
        logging.info(f"[NOTION MEMORY] ì €ì¥ ì„±ê³µ: {response.json().get('id')}")

def fetch_pending_todos():
    now = datetime.now(KST)
    today_weekday = now.strftime("%a")
    current_time = now.time()

    response = notion.databases.query(
        database_id=TODO_DATABASE_ID,
        filter={
            "and": [
                {"property": "ì™„ë£Œ ì—¬ë¶€", "checkbox": {"equals": False}},
                {
                    "or": [
                        {"property": "ë°˜ë³µ", "select": {"equals": "ë§¤ì¼"}},
                        {
                            "and": [
                                {"property": "ë°˜ë³µ", "select": {"equals": "ë§¤ì£¼"}},
                                {"property": "ìš”ì¼", "multi_select": {"contains": today_weekday}}
                            ]
                        }
                    ]
                }
            ]
        }
    )
    
    valid_tasks = []
    for page in response["results"]:
        time_str = page["properties"].get("êµ¬ì²´ì ì¸ ì‹œê°„", {}).get("rich_text", [])
        parsed_time = None
        if time_str and time_str[0]["plain_text"]:
            parsed_time = parse_time_string(time_str[0]["plain_text"])

        # êµ¬ì²´ì ì¸ ì‹œê°„ì´ ë¹„ì—ˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš° â†’ ì‹œê°„ëŒ€ë§Œ ê°€ì§€ê³  í†µê³¼
        if parsed_time is None or parsed_time <= current_time:
            valid_tasks.append(page)

    print(f"[DEBUG] âœ… {len(valid_tasks)}ê°œì˜ í•  ì¼ì´ í˜„ì¬ ì‹œê°„ ê¸°ì¤€ ì¡°ê±´ì„ ì¶©ì¡±í•¨")
    return valid_tasks

def reset_daily_todos():
    response = notion.databases.query(
        database_id=TODO_DATABASE_ID,
        # ì¡°ê±´ 1: ë§¤ì¼ ë°˜ë³µ
    daily_filter = {"property": "ë°˜ë³µ", "select": {"equals": "ë§¤ì¼"}}

    # ì¡°ê±´ 2: ë§¤ì£¼ ë°˜ë³µ + ì˜¤ëŠ˜ ìš”ì¼ í¬í•¨ (ì¡°ê±´ë¶€ ìƒì„±)
    weekly_filter = {
        "and": [
            {"property": "ë°˜ë³µ", "select": {"equals": "ë§¤ì£¼"}},
            {"property": "ìš”ì¼", "multi_select": {"contains": today_weekday}}
        ]
    }

    # ìš”ì¼ ìœ íš¨í•  ë•Œë§Œ or ì¡°ê±´ì— í¬í•¨
    filter_or_conditions = [daily_filter, weekly_filter]

    response = notion.databases.query(
        database_id=TODO_DATABASE_ID,
        filter={
            "and": [
                {"property": "ì™„ë£Œ ì—¬ë¶€", "checkbox": {"equals": False}},
                {"or": filter_or_conditions}
            ]
        }
    )

    for page in response["results"]:
        page_id = page["id"]
        try:
            notion.pages.update(page_id=page_id, properties={
                "ì™„ë£Œ ì—¬ë¶€": {"checkbox": False}
            })
            print(f"[DEBUG] âœ… {page_id} ì™„ë£Œ ì—¬ë¶€ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"[ERROR] âŒ {page_id} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

def mark_reminder_sent(page_id, attempts=1):
    now = datetime.datetime.now(KST).isoformat()
    try:
        notion.pages.update(page_id=page_id, properties={
            "ë¦¬ë§ˆì¸ë“œ ì‹œë„ ìˆ˜": {"number": attempts},
            "ë§ˆì§€ë§‰ ì²´í¬ ì‹œê°„": {"date": {"start": now}}
        })
        print(f"[DEBUG] ğŸ•’ ë¦¬ë§ˆì¸ë” ì „ì†¡ ê¸°ë¡ ì—…ë°ì´íŠ¸ ì™„ë£Œ for {page_id}")
    except Exception as e:
        print(f"[ERROR] âŒ ë¦¬ë§ˆì¸ë” ê¸°ë¡ ì‹¤íŒ¨: {e}")

def update_task_completion(page_id, done=True):
    try:
        notion.pages.update(page_id=page_id, properties={
            "ì™„ë£Œ ì—¬ë¶€": {"checkbox": done}
        })
        logging.debug(f"[NOTION] âœ… ì™„ë£Œ ì—¬ë¶€ ì—…ë°ì´íŠ¸ë¨ (page: {page_id})")
    except Exception as e:
        logging.error(f"[NOTION] âŒ ì™„ë£Œ ì—¬ë¶€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {repr(e)}")
